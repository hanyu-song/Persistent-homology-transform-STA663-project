{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STA 663 Final Project\n",
    "===\n",
    "Final Report\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1:  Basic Information\n",
    "---\n",
    "Group members:  Hanyu Song, Azeem Zaman\n",
    "\n",
    "Paper:  Persistent homology transform for modeling shapes and surfaces\n",
    "\n",
    "Authors:  Turner, Katharine; Mukherjee, Sayan; Boyer, Doug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2:  Project Abstract\n",
    "---\n",
    "### Abstract\n",
    "Our goal was to develop a package to implement the results of the paper by Turner et. al. In particular, we wrote codes to compute the persistent homology transform (PHT) of an object in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$. PHT is a statistic that completely describes a shape or surface and allows us to determine a metric on the space of piecewise linear shapes, thereby possibly useful for statistical analysis such as clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The paper introduces a tool that can be used to perform statistical shape analysis on objects in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$.  The result can be of interest to topological data analysists (TDA), researchers modeling shapes (such as medical imaging) and morphologists. One of the paper authors use this to compute the distance between heel bones in primates to generate a tree, which can be compared with a tree generated from the genetic distances between primate species.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3:  Code\n",
    "---\n",
    "This section contains a general description of each function, including:\n",
    "1.  A function to read in files containing the data\n",
    "2.  A function to construct a persistence diagram given a direction\n",
    "3.  A function to calculate the distance between persistence diagrams\n",
    "4.  Functions to generate directions for the construction of persistence diagrams\n",
    "\n",
    "### a. Modules requirement\n",
    "\n",
    "The following packages are required for implementation: `math`, `multiprocessing`, `numpy`, `scipy`, `glob` and `numba`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b. Functions for reading in Shapes\n",
    "\n",
    "Two functions for reading in data are included in the package. The first `read_file` is for reading in text files saved with raw shape data; the second `read_closed_shape` is used to read Matlab `.mat` files saved with closed shape data. Note that each file contains the data of only one shape. Both functions can read all relevant files in a specified directory; both return a list of vertices and edges of each shape, with the vertices and edges saved in two separate `numpy.ndarray`'s.\n",
    "\n",
    "The usage of each function are explained in further details below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   (1)  `read_file(list_files, d)` : Reads in raw shape data files. \n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_files`: A list of text file names. Each file is saved with the raw shape data from one shape. \n",
    "\n",
    "`d`: The dimension of the shape, either 2 or 3. \n",
    "\n",
    "a. Note that a single dimension parameter is required because we will only compute distances between shapes with the same dimension. It does not make sense to compare objects in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$.\n",
    "\n",
    "b. Text files are required to be structured as follows:\n",
    "1.  The first line should contain two numbers. The first number is the number of vertices in the shape, and the second is the number of edges.\n",
    "2.  The next lines contain the coordinates of the vertices, one per line. The points should be seperated by spaces.\n",
    "3.  The last set of lines should contain two integers, representing vertices that have an edge in between.\n",
    "\n",
    "An example file is given below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4 4 <- Number of vertices, number of edges\n",
    "    -1 1 <- vertex 1\n",
    "    1 1\n",
    "    1 -1\n",
    "    -1 -1 <- vertex 4\n",
    "    1 2 <- edge from 1 to 2\n",
    "    2 3\n",
    "    3 4\n",
    "    4 1 <- edge from 4 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Returns:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains coordinates of the vertices of one shape; the second contains the location of the edges of the shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function `read_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_files(list_files, d):\n",
    "\t\"\"\"\n",
    "    This function reads in text files saved with raw shape data, and \n",
    "    outputs information vertices and edges of each shape in a list.\n",
    "       \n",
    "    Args:\n",
    "        list_files (list): a list of text file names. Each file is \n",
    "                            saved with the raw shape data of one shape.\n",
    "        d (int): The dimension of the shape, either 2 or 3. \n",
    "    Returns:\n",
    "        list_objects: a list of lists of numpy.ndarray, i.e.Each \n",
    "                        embedded list contains two `numpy.ndarray`'s:\n",
    "                        the first array contains coordinates of all the \n",
    "                        vertices in one shape; the second contains \n",
    "                        the location of the edges in the shape \n",
    "                        (e.g., array([1,2]) means there exists an edge \n",
    "                        between vertex 1 and 2).\n",
    "\t\"\"\"\n",
    "\n",
    "\tlist_objects = []\n",
    "\tfor cur_file in list_files:\n",
    "\t\twith open(cur_file, \"r\") as f:\n",
    "\t\t\tline = f.readline()\n",
    "\t\t\tsplitline = line.split()\n",
    "\t\t\tnum_vert = int(splitline[0])\n",
    "\t\t\tnum_edges = int(splitline[1])\n",
    "\n",
    "\t\t\tvertices = np.empty((num_vert, d))\n",
    "\t\t\tedges = np.empty((num_edges, 2))\n",
    "\n",
    "\t\t\t# dictionary of vertices {i: v_i}\n",
    "\n",
    "\t\t\tfor i in range(num_vert):\n",
    "\t\t\t\tline = f.readline()\n",
    "\t\t\t\tsplitline = line.split()\n",
    "\t\t\t\tnumeric_line = [float(x) for x in splitline]\n",
    "\t\t\t\tvertices[i,:] = np.array(numeric_line)\n",
    "\t\t\tfor i in range(num_edges):\n",
    "\t\t\t\tline = f.readline()\n",
    "\t\t\t\tsplitline = line.split()\n",
    "\t\t\t\tnumeric_line = [float(x) for x in splitline]\n",
    "\t\t\t\tedges[i,:] = np.array(numeric_line)\n",
    "\t\t\tlist_objects.append([vertices, edges])\n",
    "\treturn(list_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "An example of implementation is given below. Two text file names `'test_obj','test_obj2'` are included in the `list_files`. Each file contains data of shape in $\\mathbb{R}^2$, hence $d = 2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[-1.,  1.],\n",
       "         [-1., -1.],\n",
       "         [ 1.,  1.],\n",
       "         [ 1., -1.]]), array([[ 1.,  2.],\n",
       "         [ 1.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 2.,  4.]])], [array([[ 0., -1.],\n",
       "         [ 0.,  0.],\n",
       "         [ 1.,  1.],\n",
       "         [ 2.,  0.],\n",
       "         [ 3.,  0.],\n",
       "         [ 3.,  1.],\n",
       "         [ 2., -1.]]), array([[ 1.,  2.],\n",
       "         [ 2.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 4.,  5.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  5.]])]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = read_files(list_files = ['test_obj','test_obj2'],d = 2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the function returns a list of two lists. The first embedded list contains two `numpy.ndarray`'s. The first array \n",
    "\n",
    "`array([[-1.,  1.],\n",
    "        [-1., -1.],\n",
    "        [ 1.,  1.],\n",
    "        [ 1., -1.]])` \n",
    "        \n",
    "contains the coordinates of vertices of the shape from the first file `text_obj`.\n",
    "\n",
    "The second array `array([[ 1.,  2.]` is the location of the edges in the shape, namely an edge exists between vertex 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)  `read_closed_shape(directory) `: Reads in data of closed shapes save in `.mat` format. \n",
    "\n",
    "This function assumes that the shapes are closed, by which we mean that each vertex it connected to the next vertex (i.e.vertex $n$ is connected to vertex $n+1$) and the last vertex is connected to the first.  This is a very specific function, but also a common format used in image analysis.  \n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`directory`: Path to the directory where all the relevant `.mat` files are saved.\n",
    "\n",
    "##### Returns:\n",
    "`shapes`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.\n",
    "\n",
    "##### Function  `read_closed_shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_closed_shapes(directory):\n",
    "\t\"\"\"\n",
    "\tThis function reads in all .mat files a specified directory. \n",
    "    It assumes that the shapes are closed, by which we mean that \n",
    "    each vertex it connected to the next vertex (i.e.vertex $n$ \n",
    "    is connected to vertex $n+1$) and the last vertex is connected \n",
    "    to the first.  \n",
    "    \n",
    "    Args: \n",
    "        directory (string): the path to the directory. When referring\n",
    "        to the current directory, simply use \"./\".\n",
    "    Returns:\n",
    "        shapes (list): A list of lists. Each embedded list contains \n",
    "        two `numpy.ndarray`'s: the first array contains the coordinates \n",
    "        of the vertices in one shape; the second contains the location \n",
    "        of the edges in the shape.\n",
    "        \n",
    "\t\"\"\"\n",
    "\tquery = directory + \"*.mat\"\n",
    "\tfiles = glob.glob(query)\n",
    "\tshapes = []\n",
    "\tfor file in files:\n",
    "\t\tvertices = sio.loadmat(file)['x']\n",
    "\t\tN = vertices.shape[0]\n",
    "\t\tedges = np.zeros((N,2))\n",
    "\t\tedges[N-1,:] = np.array([N, 1])\n",
    "\t\tfor i in range(N-1):\n",
    "\t\t\tedges[i,:] = np.array([i+1, i+2])\n",
    "\t\tshapes.append([vertices, edges])\n",
    "\treturn shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "The example below demonstrates reading in all the `.mat` files in the current directory. As can be seen, the function returns a list of one list. The embedded list contains two `numpy.ndarray`'s. The first array contains the vertices coordinates of the shape from file `Class1_Sample1.mat`. The second array is the location of the edges in the shape, e.g., an edge exists between vertex 1 and 2, vertex 2 and 3. (Indeed this is a closed shape, so vertex $n$ is connected to vertex $n+1$, for all $n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_closed_shp = read_closed_shapes('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2 101]\n",
      " [  3 100]\n",
      " [  4 100]\n",
      " [  5  99]\n",
      " [  6  98]\n",
      " [  7  98]\n",
      " [  8  98]\n",
      " [  9  97]\n",
      " [  9  96]\n",
      " [ 10  95]\n",
      " [ 10  94]\n",
      " [ 10  93]\n",
      " [ 10  92]\n",
      " [ 10  91]\n",
      " [ 10  90]\n",
      " [ 10  89]\n",
      " [ 10  88]\n",
      " [ 10  87]\n",
      " [ 10  86]\n",
      " [ 11  85]\n",
      " [ 11  84]\n",
      " [ 11  83]\n",
      " [ 11  82]\n",
      " [ 11  81]\n",
      " [ 11  80]\n",
      " [ 11  79]\n",
      " [ 11  78]\n",
      " [ 11  77]\n",
      " [ 11  76]\n",
      " [ 12  75]\n",
      " [ 13  76]\n",
      " [ 14  75]\n",
      " [ 15  74]\n",
      " [ 14  73]\n",
      " [ 13  72]\n",
      " [ 14  71]\n",
      " [ 15  70]\n",
      " [ 16  69]\n",
      " [ 17  68]\n",
      " [ 18  67]\n",
      " [ 19  66]\n",
      " [ 19  65]\n",
      " [ 19  64]\n",
      " [ 20  64]\n",
      " [ 21  64]\n",
      " [ 22  63]\n",
      " [ 23  62]\n",
      " [ 23  61]\n",
      " [ 24  60]\n",
      " [ 24  59]\n",
      " [ 25  58]\n",
      " [ 26  58]\n",
      " [ 27  58]\n",
      " [ 28  57]\n",
      " [ 29  57]\n",
      " [ 30  56]\n",
      " [ 30  55]\n",
      " [ 31  55]\n",
      " [ 32  54]\n",
      " [ 33  54]\n",
      " [ 34  54]\n",
      " [ 35  53]\n",
      " [ 35  52]\n",
      " [ 34  51]\n",
      " [ 35  51]\n",
      " [ 36  51]\n",
      " [ 37  50]\n",
      " [ 38  49]\n",
      " [ 39  49]\n",
      " [ 40  49]\n",
      " [ 41  48]\n",
      " [ 42  47]\n",
      " [ 42  46]\n",
      " [ 42  45]\n",
      " [ 43  45]\n",
      " [ 44  45]\n",
      " [ 45  44]\n",
      " [ 46  43]\n",
      " [ 47  42]\n",
      " [ 48  41]\n",
      " [ 48  40]\n",
      " [ 48  39]\n",
      " [ 48  38]\n",
      " [ 49  37]\n",
      " [ 50  36]\n",
      " [ 51  35]\n",
      " [ 52  34]\n",
      " [ 53  33]\n",
      " [ 54  33]\n",
      " [ 55  32]\n",
      " [ 56  31]\n",
      " [ 55  30]\n",
      " [ 56  30]\n",
      " [ 57  29]\n",
      " [ 57  28]\n",
      " [ 57  27]\n",
      " [ 58  26]\n",
      " [ 58  25]\n",
      " [ 59  25]\n",
      " [ 60  24]\n",
      " [ 60  23]\n",
      " [ 61  22]\n",
      " [ 60  21]\n",
      " [ 59  20]\n",
      " [ 59  19]\n",
      " [ 60  18]\n",
      " [ 61  17]\n",
      " [ 61  16]\n",
      " [ 61  15]\n",
      " [ 62  14]\n",
      " [ 63  13]\n",
      " [ 63  12]\n",
      " [ 63  11]\n",
      " [ 64  11]\n",
      " [ 65  10]\n",
      " [ 66  10]\n",
      " [ 67   9]\n",
      " [ 67   8]\n",
      " [ 67   7]\n",
      " [ 68   7]\n",
      " [ 69   7]\n",
      " [ 70   7]\n",
      " [ 71   8]\n",
      " [ 72   9]\n",
      " [ 73  10]\n",
      " [ 74  10]\n",
      " [ 75  11]\n",
      " [ 76  11]\n",
      " [ 75  12]\n",
      " [ 76  13]\n",
      " [ 77  14]\n",
      " [ 78  15]\n",
      " [ 79  16]\n",
      " [ 80  16]\n",
      " [ 81  16]\n",
      " [ 81  17]\n",
      " [ 81  18]\n",
      " [ 82  19]\n",
      " [ 83  20]\n",
      " [ 84  20]\n",
      " [ 85  20]\n",
      " [ 85  21]\n",
      " [ 85  22]\n",
      " [ 86  23]\n",
      " [ 87  24]\n",
      " [ 88  25]\n",
      " [ 89  26]\n",
      " [ 89  27]\n",
      " [ 89  28]\n",
      " [ 90  29]\n",
      " [ 91  30]\n",
      " [ 91  31]\n",
      " [ 91  32]\n",
      " [ 92  33]\n",
      " [ 93  33]\n",
      " [ 94  34]\n",
      " [ 94  35]\n",
      " [ 95  36]\n",
      " [ 96  37]\n",
      " [ 97  38]\n",
      " [ 98  39]\n",
      " [ 99  40]\n",
      " [ 98  41]\n",
      " [ 99  42]\n",
      " [100  43]\n",
      " [101  43]\n",
      " [102  42]\n",
      " [103  42]\n",
      " [104  42]\n",
      " [105  42]\n",
      " [106  43]\n",
      " [107  43]\n",
      " [108  44]\n",
      " [109  44]\n",
      " [110  45]\n",
      " [111  46]\n",
      " [112  47]\n",
      " [112  48]\n",
      " [113  49]\n",
      " [113  50]\n",
      " [113  51]\n",
      " [113  52]\n",
      " [113  53]\n",
      " [113  54]\n",
      " [113  55]\n",
      " [113  56]\n",
      " [113  57]\n",
      " [112  58]\n",
      " [112  59]\n",
      " [111  60]\n",
      " [110  61]\n",
      " [111  62]\n",
      " [112  63]\n",
      " [112  64]\n",
      " [112  65]\n",
      " [113  66]\n",
      " [114  66]\n",
      " [114  67]\n",
      " [114  68]\n",
      " [114  69]\n",
      " [115  70]\n",
      " [116  70]\n",
      " [117  71]\n",
      " [117  72]\n",
      " [118  73]\n",
      " [118  74]\n",
      " [119  75]\n",
      " [119  76]\n",
      " [119  77]\n",
      " [118  78]\n",
      " [119  79]\n",
      " [120  80]\n",
      " [120  81]\n",
      " [120  82]\n",
      " [121  83]\n",
      " [122  84]\n",
      " [121  85]\n",
      " [122  86]\n",
      " [123  87]\n",
      " [123  88]\n",
      " [123  89]\n",
      " [123  90]\n",
      " [124  91]\n",
      " [124  92]\n",
      " [125  93]\n",
      " [126  94]\n",
      " [125  95]\n",
      " [126  96]\n",
      " [127  97]\n",
      " [127  98]\n",
      " [127  99]\n",
      " [127 100]\n",
      " [127 101]\n",
      " [126 102]\n",
      " [125 103]\n",
      " [124 103]\n",
      " [123 103]\n",
      " [122 103]\n",
      " [121 103]\n",
      " [120 103]\n",
      " [119 103]\n",
      " [118 102]\n",
      " [117 102]\n",
      " [116 103]\n",
      " [115 103]\n",
      " [114 103]\n",
      " [113 103]\n",
      " [112 102]\n",
      " [111 102]\n",
      " [110 102]\n",
      " [109 102]\n",
      " [108 102]\n",
      " [107 102]\n",
      " [106 101]\n",
      " [105 101]\n",
      " [104 101]\n",
      " [103 101]\n",
      " [102 101]\n",
      " [101 101]\n",
      " [100 101]\n",
      " [ 99 101]\n",
      " [ 98 101]\n",
      " [ 97 101]\n",
      " [ 96 102]\n",
      " [ 95 102]\n",
      " [ 94 103]\n",
      " [ 93 103]\n",
      " [ 92 104]\n",
      " [ 91 104]\n",
      " [ 90 105]\n",
      " [ 89 105]\n",
      " [ 88 106]\n",
      " [ 87 107]\n",
      " [ 86 106]\n",
      " [ 85 106]\n",
      " [ 84 106]\n",
      " [ 83 107]\n",
      " [ 82 107]\n",
      " [ 81 107]\n",
      " [ 80 108]\n",
      " [ 79 109]\n",
      " [ 78 110]\n",
      " [ 77 111]\n",
      " [ 76 111]\n",
      " [ 75 111]\n",
      " [ 74 111]\n",
      " [ 73 111]\n",
      " [ 72 112]\n",
      " [ 71 112]\n",
      " [ 70 113]\n",
      " [ 69 113]\n",
      " [ 68 113]\n",
      " [ 67 114]\n",
      " [ 66 114]\n",
      " [ 65 115]\n",
      " [ 64 116]\n",
      " [ 63 116]\n",
      " [ 62 117]\n",
      " [ 61 116]\n",
      " [ 60 117]\n",
      " [ 59 117]\n",
      " [ 58 118]\n",
      " [ 57 118]\n",
      " [ 56 118]\n",
      " [ 55 118]\n",
      " [ 54 119]\n",
      " [ 53 119]\n",
      " [ 52 120]\n",
      " [ 52 121]\n",
      " [ 51 121]\n",
      " [ 50 122]\n",
      " [ 49 121]\n",
      " [ 48 121]\n",
      " [ 47 120]\n",
      " [ 46 121]\n",
      " [ 45 122]\n",
      " [ 44 122]\n",
      " [ 43 122]\n",
      " [ 42 122]\n",
      " [ 41 122]\n",
      " [ 40 122]\n",
      " [ 39 121]\n",
      " [ 38 121]\n",
      " [ 37 122]\n",
      " [ 36 122]\n",
      " [ 35 122]\n",
      " [ 34 121]\n",
      " [ 33 121]\n",
      " [ 32 121]\n",
      " [ 31 120]\n",
      " [ 30 120]\n",
      " [ 30 119]\n",
      " [ 29 118]\n",
      " [ 28 118]\n",
      " [ 28 117]\n",
      " [ 27 116]\n",
      " [ 26 116]\n",
      " [ 25 115]\n",
      " [ 24 116]\n",
      " [ 24 117]\n",
      " [ 24 118]\n",
      " [ 23 119]\n",
      " [ 22 120]\n",
      " [ 21 121]\n",
      " [ 20 122]\n",
      " [ 19 122]\n",
      " [ 18 122]\n",
      " [ 17 122]\n",
      " [ 16 122]\n",
      " [ 15 122]\n",
      " [ 14 122]\n",
      " [ 13 122]\n",
      " [ 12 121]\n",
      " [ 11 121]\n",
      " [ 10 121]\n",
      " [  9 120]\n",
      " [  8 120]\n",
      " [  7 119]\n",
      " [  6 118]\n",
      " [  5 117]\n",
      " [  5 116]\n",
      " [  4 115]\n",
      " [  4 114]\n",
      " [  4 113]\n",
      " [  3 112]\n",
      " [  2 111]\n",
      " [  2 110]\n",
      " [  2 109]\n",
      " [  2 108]\n",
      " [  2 107]\n",
      " [  2 106]\n",
      " [  2 105]\n",
      " [  2 104]\n",
      " [  2 103]\n",
      " [  2 102]]\n"
     ]
    }
   ],
   "source": [
    "print(res_closed_shp[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Functions for persistence diagram construction \n",
    "\n",
    "A function to construct a persistence diagram given a direction is included in the package. The functionality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A persistence diagram is a filtration.  We start with an object and \"build\" the object in a certain direction.  We record when each point in the object first appears (is \"born\") and when it merges into an object that already exists (it \"dies).  Consider the shape below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](full_fig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct this figure in the direction $v = (0,1)$.  If we imagine moving upwards across the figure, the first height at which we will see any points of the diagram is $h=-1$.  We see that vertices 1 and 7 are born at $h = -1$, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![h1](persist_diag1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next height at which something something interesting happens is $h = 0$, at which time three more points are born.  All of these points, however, die immediately.  Vertex 2 merges with vertex 1 and vertices 4 and 5 merge with vertex 7.  At this time we have two unconnected components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](persist_diag2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we reach $h = 1$, we have finished constructing the diagram.  Vertex 6 dies immediately because it merges with vertex 5.  Vertex 3 joints the two components that were previously disjoint.  Since vertices 1 and 7 were both born at $h=-1$, we make a convention that lower numbered vertices will be considered the root and higher numbered vertices will merge with them.  Thus at time $h=1$ vertex 7 dies, as it merges with vertex 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig3](persist_diag3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the persistence diagram is given below.  The red point represents vertex 1, which never dies.  We consider the point to be at $(-1,\\infty)$.  The line in the figure is the diagonal.  A point on the diagonal is one that is born and dies at the same instant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diagram](diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impliment this process of constructing persistene diagrams, we need to be able to tell when a vertex is born and when the vertex merges with another component.  For a fixed direction $v$ (which we will always take to be unit length), we can easily determien the height of a vertex.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "\tdef __init__(self, name):\n",
    "\t\tself.parent = self\n",
    "\t\tself.name = name\n",
    "\t\tself.rank = 0\n",
    "\t\n",
    "def Find(x):\n",
    "\t\"\"\"\n",
    "\tThis function determines the root of the tree\n",
    "\tthat x is in.  It works recursively. x should\n",
    "\tbe an object of class Tree.\n",
    "\t\"\"\"\n",
    "\tif x.parent != x:\n",
    "\t\tx.parent = Find(x.parent)\t\n",
    "\treturn x.parent\n",
    "\n",
    "def height_Union(x, y, dict_heights):\n",
    "\t\"\"\"\n",
    "\tThis function takes the union of two nodes.\n",
    "\tIt does this by changing the root one tree\n",
    "\tto be the root of the other tree.  It changes the\n",
    "\troot based on height.  The root becomes the node with\n",
    "\tthe lowest height.  So the node that is born first\n",
    "\tbecomes the root.  \n",
    "\n",
    "\tIf the two roots have the same height, the lowest \n",
    "\tnumber becomes the root.  For example, if we have vertex\n",
    "\t1 and vertix 3 at the same height, vertex 1 will become\n",
    "\tthe root.  \n",
    "\n",
    "\tInputs:\n",
    "\t\tx,y:  objects of Tree class\n",
    "\t\tdict_heights:  a map v-> h, where v is a vertex,\n",
    "\t\twhich should be the .name of some tree and h is\n",
    "\t\tthe height with respect to some direction\n",
    "\t\"\"\"\n",
    "\tx_root = Find(x)\n",
    "\ty_root = Find(y)\n",
    "\tif x_root == y_root:\n",
    "\t\treturn None\n",
    "\tif dict_heights[x_root.name] < dict_heights[y_root.name]:\n",
    "\t\ty_root.parent = x_root\n",
    "\telif dict_heights[x_root.name] == dict_heights[y_root.name]:\n",
    "\t\tif x.name < y.name:\n",
    "\t\t\ty_root.parent = x_root\n",
    "\t\telse:\n",
    "\t\t\tx_root.parent = y_root\n",
    "\telse:\n",
    "\t\tx_root.parent = y_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.  A function for distance computation between persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Algorithms\n",
    "---\n",
    "One algorithm used is the Hungarian (or Munkres) algorithm.  The alogirthm is used in situations where assignments with an associated cost must be made and the goal is to select the assignment to minimize the cost.  Here we use this algorithm to calculate the distance between persistence diagrams. The distance between persistence diagrams is the sum of the distances between the points of the first persistence diagram paired with the points of the second diagram and additional points on the diagonal.  Selecting the pairing that minimzies this distance can be achieved using the Munkres algorithm.\n",
    "\n",
    "Another algorithm used in our code is the Union-Find algorithm.  This algorithm is used in the construction of the persistence diagrams. During the construction we must keep track of when disjoint components merge.  We view each component as a tree.  When two components merge we join the roots of the trees.  This allows us to find when disjoint components merge.\n",
    "\n",
    "Section 4:  Tests\n",
    "---\n",
    "Write some tests. In particular, compare results from our codes to results in the paper to ensure that our codes yield the same results.  Test on simple simulated data.\n",
    "\n",
    "Section 5:  Optimization\n",
    "---\n",
    "We tried optimizing the performance of the codes using `numba` just-in-time (JIT) compilation, `Cython`, embarrasingly parallel processing. Based on the input file `Class1_Sample1.mat`, most functions perform very well, taking only miliseconds to process such a shape with $375$ vertices. Assuming we want to measure the distance between such a shape to another shape with $375$ vertices, it takes $33.6s$ for the current Munkres algorithm to finish running, suggesting room for improvement.\n",
    "\n",
    "We used the function `linear_sum_assignment` (Source: https://github.com/scipy/scipy/blob/master/scipy/optimize/_hungarian.py#L13-L107`scipy) from `scipy.optimize`. To improve its performance, we tried numba JIT computation, simple compilation in `Cython`, cythonizing via static typing and `cnumpy` iteration and wrapping `C` codes. However, no correct and easily accessible `C` or `C++` functions have been found. Neither have we achieve significant improvement in `Python`. Specifically, the major problem in cythonizing concerns the fast array declarations in `cdef` classes. Fast array declarations, however, are currently not accessible in the fields of cdef classes or as global variables, according to Cython documentation\n",
    "(ref: http://cython.readthedocs.io/en/latest/src/tutorial/numpy.html).\n",
    "\n",
    "We benchmarked the different optimization strategies based on a $1,000 \\times 1,000$ cost matrix. The performances are  summarised in the table below:\n",
    "\n",
    "|  | original function | numba JIT  | Simple Cython compilation | Cythonizing via static typing & `cNumPy` |\n",
    "|-----------|-------------------|------------|---------------------------|------------------------------------------|\n",
    "| Wall time | 1 min 41 s        | 1 min 27 s | 1 min 46 s                | 1 min 42 s                               |\n",
    "\n",
    "\n",
    "As can be seen from the above table, no consistent outperformance has been achieved. We will continue to improve the performance during summer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
