{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STA 663 Final Project\n",
    "===\n",
    "Final Report\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1:  Basic Information\n",
    "---\n",
    "Group members:  Hanyu Song, Azeem Zaman\n",
    "\n",
    "Paper:  Persistent homology transform for modeling shapes and surfaces\n",
    "\n",
    "Authors:  Turner, Katharine; Mukherjee, Sayan; Boyer, Doug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2:  Project Abstract\n",
    "---\n",
    "### Abstract\n",
    "Our goal was to develop a package to implement the results of the paper by Turner et. al. In particular, we wrote codes to compute the persistent homology transform (PHT) of an object in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$. PHT is a statistic that completely describes a shape or surface and allows us to determine a metric on the space of piecewise linear shapes, thereby possibly useful for statistical analysis such as clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The paper introduces a tool that can be used to perform statistical shape analysis on objects in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$.  The result can be of interest to topological data analysists (TDA), researchers modeling shapes (such as medical imaging) and morphologists. One of the paper authors use this to compute the distance between heel bones in primates to generate a tree, which can be compared with a tree generated from the genetic distances between primate species.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3:  Code\n",
    "---\n",
    "This section contains a general description of each function, including:\n",
    "1.  A function to read in files containing the data\n",
    "2.  A function to construct a persistence diagram given a direction\n",
    "3.  A function to calculate the distance between persistence diagrams\n",
    "4.  Functions to generate directions for the construction of persistence diagrams\n",
    "\n",
    "### a. Modules requirement\n",
    "\n",
    "The following packages are required for implementation: `math`, `multiprocessing`, `numpy`, `scipy`, `glob` and `numba`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b. Functions for reading in Shapes\n",
    "\n",
    "Two functions for reading in data are included in the package. The first `read_file` is for reading in text files saved with raw shape data; the second `read_closed_shape` is used to read Matlab `.mat` files saved with closed shape data. Note that each file contains the data of only one shape. Both functions can read all relevant files in a specified directory; both return a list of vertices and edges of each shape, with the vertices and edges saved in two separate `numpy.ndarray`'s.\n",
    "\n",
    "The usage of each function are explained in further details below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   (1)  `read_file(list_files, d)` : Reads in raw shape data files. \n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_files`: A list of text file names. Each file is saved with the raw shape data from one shape. \n",
    "\n",
    "`d`: The dimension of the shape, either 2 or 3. \n",
    "\n",
    "a. Note that a single dimension parameter is required because we will only compute distances between shapes with the same dimension. It does not make sense to compare objects in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$.\n",
    "\n",
    "b. Text files are required to be structured as follows:\n",
    "1.  The first line should contain two numbers. The first number is the number of vertices in the shape, and the second is the number of edges.\n",
    "2.  The next lines contain the coordinates of the vertices, one per line. The points should be seperated by spaces.\n",
    "3.  The last set of lines should contain two integers, representing vertices that have an edge in between.\n",
    "\n",
    "An example file is given below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4 4 <- Number of vertices, number of edges\n",
    "    -1 1 <- vertex 1\n",
    "    1 1\n",
    "    1 -1\n",
    "    -1 -1 <- vertex 4\n",
    "    1 2 <- edge from 1 to 2\n",
    "    2 3\n",
    "    3 4\n",
    "    4 1 <- edge from 4 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Returns:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the vertices of one shape; the second contains the edges of the shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function `read_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files(list_files, d):\n",
    "\tlist_objects = []\n",
    "\tfor cur_file in list_files:\n",
    "\t\twith open(cur_file, \"r\") as f:\n",
    "\t\t\tline = f.readline()\n",
    "\t\t\tsplitline = line.split()\n",
    "\t\t\tnum_vert = int(splitline[0])\n",
    "\t\t\tnum_edges = int(splitline[1])\n",
    "\n",
    "\t\t\tvertices = np.empty((num_vert, d))\n",
    "\t\t\tedges = np.empty((num_edges, 2))\n",
    "\n",
    "\t\t\t# dictionary of vertices {i: v_i}\n",
    "\n",
    "\t\t\tfor i in range(num_vert):\n",
    "\t\t\t\tline = f.readline()\n",
    "\t\t\t\tsplitline = line.split()\n",
    "\t\t\t\tnumeric_line = [float(x) for x in splitline]\n",
    "\t\t\t\tvertices[i,:] = np.array(numeric_line)\n",
    "\t\t\tfor i in range(num_edges):\n",
    "\t\t\t\tline = f.readline()\n",
    "\t\t\t\tsplitline = line.split()\n",
    "\t\t\t\tnumeric_line = [float(x) for x in splitline]\n",
    "\t\t\t\tedges[i,:] = np.array(numeric_line)\n",
    "\t\t\tlist_objects.append([vertices, edges])\n",
    "\treturn(list_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "An example of implementation is given below. Two text file names `'test_obj','test_obj2'` are included in the `list_files`. Each file contains data of shape in $\\mathbb{R}^2$, hence $d = 2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[-1.,  1.],\n",
       "         [-1., -1.],\n",
       "         [ 1.,  1.],\n",
       "         [ 1., -1.]]), array([[ 1.,  2.],\n",
       "         [ 1.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 2.,  4.]])], [array([[ 0., -1.],\n",
       "         [ 0.,  0.],\n",
       "         [ 1.,  1.],\n",
       "         [ 2.,  0.],\n",
       "         [ 3.,  0.],\n",
       "         [ 3.,  1.],\n",
       "         [ 2., -1.]]), array([[ 1.,  2.],\n",
       "         [ 2.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 4.,  5.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  5.]])]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = read_files(list_files = ['test_obj','test_obj2'],d = 2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the function returns a list of two lists. The first embedded list contains two `numpy.ndarray`'s. The first array \n",
    "\n",
    "`array([[-1.,  1.],\n",
    "        [-1., -1.],\n",
    "        [ 1.,  1.],\n",
    "        [ 1., -1.]])` \n",
    "        \n",
    "contains the coordinates of vertices of the shape from the first file `text_obj`.\n",
    "\n",
    "The second array `array([[ 1.,  2.]` is the location of the edges in the shape, namely an edge exists between vertex 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)  `read_closed_shape(directory) `: Reads in data of shapes save in `.mat` format.\n",
    "\n",
    "The other function, `read_closed_shape`, is used to read Matlab `.mat` files.  It reads all `.mat` files in a specified directory.  This function assumes that the shapes are closed, by which we mean that each vertex it connected to the next vertex (i.e.vertex $n$ is connected to vertex $n+1$) and the last vertex is connected to the first.  This is a very specific function, but also a common format used in image analysis.  \n",
    "\n",
    "The function is demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_closed_shapes(directory):\n",
    "\t\"\"\"\n",
    "\tThis function reads in all .mat files a specified directory\n",
    "\t\"\"\"\n",
    "\tquery = directory + \"*.mat\"\n",
    "\tfiles = glob.glob(query)\n",
    "\tshapes = []\n",
    "\tfor file in files:\n",
    "\t\tvertices = sio.loadmat(file)['x']\n",
    "\t\tN = vertices.shape[0]\n",
    "\t\tedges = np.zeros((N,2))\n",
    "\t\tedges[N-1,:] = np.array([N, 1])\n",
    "\t\tfor i in range(N-1):\n",
    "\t\t\tedges[i,:] = np.array([i+1, i+2])\n",
    "\t\tshapes.append([vertices, edges])\n",
    "\treturn shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Algorithms\n",
    "---\n",
    "One algorithm used is the Hungarian (or Munkres) algorithm.  The alogirthm is used in situations where assignments with an associated cost must be made and the goal is the select the assignment to minimize the cost.  This algorithm is used to calculate the distance between persistence diagrams.  The distance between persistence diagrams is the distance between is the sum of the distances between the points of the first persistence diagram paired with the points of the second diagram and additional points on the diagonal.  Selecting the pairing that minimzies this distance can be achieved with the Munkres algorithm.\n",
    "\n",
    "Another algorithm used in our code is the Union-Find algorithm.  This algorithm is used in the construction of the persistence diagrams.  During the construction we must keep track of when disjoint components merge.  We view each component as a tree.  When two components merge we join the the roots of the trees.  This allows us to find when disjoint components merge.\n",
    "\n",
    "Section 4:  Tests\n",
    "---\n",
    "Write some tests. In particular, compare results from our codes to results in the paper to ensure that our codes yield the same results.  Test on simple simulated data.\n",
    "\n",
    "Section 5:  Optimization\n",
    "---\n",
    "This section will describe the steps taken to optimize the speed of the code using methods such as just-in-time compilation, Cython, and possibly alternative algorithms.\n",
    "\n",
    "Section 6:  Packaging\n",
    "---\n",
    "Prepare GitHub repo for distribution.  Prof Mukherjee expressed interest in having the code wrapped for use in R.  If we have time, we will work on this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
