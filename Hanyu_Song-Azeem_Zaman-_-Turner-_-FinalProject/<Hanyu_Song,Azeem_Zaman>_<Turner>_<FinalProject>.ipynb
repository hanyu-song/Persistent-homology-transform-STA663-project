{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STA 663 Final Project\n",
    "===\n",
    "Final Report\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1:  Basic Information\n",
    "---\n",
    "Group members:  Hanyu Song, Azeem Zaman\n",
    "\n",
    "Paper:  Persistent homology transform for modeling shapes and surfaces\n",
    "\n",
    "Authors:  Turner, Katharine; Mukherjee, Sayan; Boyer, Doug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2:  Project Abstract\n",
    "---\n",
    "### Abstract\n",
    "Our goal was to develop a package to implement the results of the paper by Turner et. al. In particular, we wrote codes to compute the persistent homology transform (PHT) of an object in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$. PHT is a statistic that completely describes a shape or surface and allows us to determine a metric on the space of piecewise linear shapes, thereby possibly useful for statistical analysis such as clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The paper introduces a tool that can be used to perform statistical shape analysis on objects in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$.  The result can be of interest to topological data analysists (TDA), researchers modeling shapes (such as medical imaging) and morphologists. One of the paper authors use this to compute the distance between heel bones in primates to generate a tree, which can be compared with a tree generated from the genetic distances between primate species.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3:  Code\n",
    "---\n",
    "This section contains a general description of each function, including:\n",
    "1.  A function to read in files containing the data\n",
    "2.  A function to construct a persistence diagram given a direction\n",
    "3.  A function to calculate the distance between persistence diagrams\n",
    "4.  Functions to generate directions for the construction of persistence diagrams\n",
    "\n",
    "### a. Modules requirement\n",
    "\n",
    "The following packages are required for implementation: `math`, `multiprocessing`, `numpy`, `scipy`, `glob` and `numba`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b. Functions for reading in Shapes\n",
    "\n",
    "Two functions for reading in data are included in the package. The first `read_file` is for reading in text files saved with raw shape data; the second `read_closed_shape` is used to read Matlab `.mat` files saved with closed shape data. Note that each file contains the data of only one shape. Both functions can read all relevant files in a specified directory; both return a list of vertices and edges of each shape, with the vertices and edges saved in two separate `numpy.ndarray`'s.\n",
    "\n",
    "The usage of each function are explained in further details below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   (1)  `read_file(list_files, d)` : Reads in raw shape data files. \n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_files`: A list of text file names. Each file is saved with the raw shape data from one shape. \n",
    "\n",
    "`d`: The dimension of the shape, either 2 or 3. \n",
    "\n",
    "a. Note that a single dimension parameter is required because we will only compute distances between shapes with the same dimension. It does not make sense to compare objects in $\\mathbb{R}^3$ and shapes in $\\mathbb{R}^2$.\n",
    "\n",
    "b. Text files are required to be structured as follows:\n",
    "1.  The first line should contain two numbers. The first number is the number of vertices in the shape, and the second is the number of edges.\n",
    "2.  The next lines contain the coordinates of the vertices, one per line. The points should be seperated by spaces.\n",
    "3.  The last set of lines should contain two integers, representing vertices that have an edge in between.\n",
    "\n",
    "An example file is given below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4 4 <- Number of vertices, number of edges\n",
    "    -1 1 <- vertex 1\n",
    "    1 1\n",
    "    1 -1\n",
    "    -1 -1 <- vertex 4\n",
    "    1 2 <- edge from 1 to 2\n",
    "    2 3\n",
    "    3 4\n",
    "    4 1 <- edge from 4 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Returns:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains coordinates of the vertices of one shape; the second contains the location of the edges of the shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function `read_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_files(list_files, d):\n",
    "\t\"\"\"\n",
    "    This function reads in text files saved with raw shape data, and \n",
    "    outputs information vertices and edges of each shape in a list.\n",
    "       \n",
    "    Args:\n",
    "        list_files (list): a list of text file names. Each file is \n",
    "                            saved with the raw shape data of one shape.\n",
    "        d (int): The dimension of the shape, either 2 or 3. \n",
    "    Returns:\n",
    "        list_objects: a list of lists of numpy.ndarray, i.e.Each \n",
    "                        embedded list contains two `numpy.ndarray`'s:\n",
    "                        the first array contains coordinates of all the \n",
    "                        vertices in one shape; the second contains \n",
    "                        the location of the edges in the shape \n",
    "                        (e.g., array([1,2]) means there exists an edge \n",
    "                        between vertex 1 and 2).\n",
    "\t\"\"\"\n",
    "\n",
    "\tlist_objects = []\n",
    "\tfor cur_file in list_files:\n",
    "\t\twith open(cur_file, \"r\") as f:\n",
    "\t\t\tline = f.readline()\n",
    "\t\t\tsplitline = line.split()\n",
    "\t\t\tnum_vert = int(splitline[0])\n",
    "\t\t\tnum_edges = int(splitline[1])\n",
    "\n",
    "\t\t\tvertices = np.empty((num_vert, d))\n",
    "\t\t\tedges = np.empty((num_edges, 2))\n",
    "\n",
    "\t\t\t# dictionary of vertices {i: v_i}\n",
    "\n",
    "\t\t\tfor i in range(num_vert):\n",
    "\t\t\t\tline = f.readline()\n",
    "\t\t\t\tsplitline = line.split()\n",
    "\t\t\t\tnumeric_line = [float(x) for x in splitline]\n",
    "\t\t\t\tvertices[i,:] = np.array(numeric_line)\n",
    "\t\t\tfor i in range(num_edges):\n",
    "\t\t\t\tline = f.readline()\n",
    "\t\t\t\tsplitline = line.split()\n",
    "\t\t\t\tnumeric_line = [float(x) for x in splitline]\n",
    "\t\t\t\tedges[i,:] = np.array(numeric_line)\n",
    "\t\t\tlist_objects.append([vertices, edges])\n",
    "\treturn(list_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "An example of implementation is given below. Two text file names `'test_obj','test_obj2'` are included in the `list_files`. Each file contains data of shape in $\\mathbb{R}^2$, hence $d = 2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[-1.,  1.],\n",
       "         [-1., -1.],\n",
       "         [ 1.,  1.],\n",
       "         [ 1., -1.]]), array([[ 1.,  2.],\n",
       "         [ 1.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 2.,  4.]])], [array([[ 0., -1.],\n",
       "         [ 0.,  0.],\n",
       "         [ 1.,  1.],\n",
       "         [ 2.,  0.],\n",
       "         [ 3.,  0.],\n",
       "         [ 3.,  1.],\n",
       "         [ 2., -1.]]), array([[ 1.,  2.],\n",
       "         [ 2.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 4.,  5.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  5.]])]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = read_files(list_files = ['test_obj','test_obj2'],d = 2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the function returns a list of two lists. The first embedded list contains two `numpy.ndarray`'s. The first array \n",
    "\n",
    "`array([[-1.,  1.],\n",
    "        [-1., -1.],\n",
    "        [ 1.,  1.],\n",
    "        [ 1., -1.]])` \n",
    "        \n",
    "contains the coordinates of vertices of the shape from the first file `text_obj`.\n",
    "\n",
    "The second array `array([[ 1.,  2.]` is the location of the edges in the shape, namely an edge exists between vertex 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)  `read_closed_shape(directory) `: Reads in data of closed shapes save in `.mat` format. \n",
    "\n",
    "This function assumes that the shapes are closed, by which we mean that each vertex it connected to the next vertex (i.e.vertex $n$ is connected to vertex $n+1$) and the last vertex is connected to the first.  This is a very specific function, but also a common format used in image analysis.  \n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`directory`: Path to the directory where all the relevant `.mat` files are saved.\n",
    "\n",
    "##### Returns:\n",
    "`shapes`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.\n",
    "\n",
    "##### Function  `read_closed_shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_closed_shapes(directory):\n",
    "\t\"\"\"\n",
    "\tThis function reads in all .mat files a specified directory. \n",
    "    It assumes that the shapes are closed, by which we mean that \n",
    "    each vertex it connected to the next vertex (i.e.vertex $n$ \n",
    "    is connected to vertex $n+1$) and the last vertex is connected \n",
    "    to the first.  \n",
    "    \n",
    "    Args: \n",
    "        directory (string): the path to the directory. When referring\n",
    "        to the current directory, simply use \"./\".\n",
    "    Returns:\n",
    "        shapes (list): A list of lists. Each embedded list contains \n",
    "        two `numpy.ndarray`'s: the first array contains the coordinates \n",
    "        of the vertices in one shape; the second contains the location \n",
    "        of the edges in the shape.\n",
    "        \n",
    "\t\"\"\"\n",
    "\tquery = directory + \"*.mat\"\n",
    "\tfiles = glob.glob(query)\n",
    "\tshapes = []\n",
    "\tfor file in files:\n",
    "\t\tvertices = sio.loadmat(file)['x']\n",
    "\t\tN = vertices.shape[0]\n",
    "\t\tedges = np.zeros((N,2))\n",
    "\t\tedges[N-1,:] = np.array([N, 1])\n",
    "\t\tfor i in range(N-1):\n",
    "\t\t\tedges[i,:] = np.array([i+1, i+2])\n",
    "\t\tshapes.append([vertices, edges])\n",
    "\treturn shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "The example below demonstrates reading in all the `.mat` files in the current directory. As can be seen, the function returns a list of one list. The embedded list contains two `numpy.ndarray`'s. The first array contains the vertices coordinates of the shape from file `Class1_Sample1.mat`. The second array is the location of the edges in the shape, e.g., an edge exists between vertex 1 and 2, vertex 2 and 3. (Indeed this is a closed shape, so vertex $n$ is connected to vertex $n+1$, for all $n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_closed_shp = read_closed_shapes('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2 101]\n",
      " [  3 100]\n",
      " [  4 100]\n",
      " [  5  99]\n",
      " [  6  98]\n",
      " [  7  98]\n",
      " [  8  98]\n",
      " [  9  97]\n",
      " [  9  96]\n",
      " [ 10  95]\n",
      " [ 10  94]\n",
      " [ 10  93]\n",
      " [ 10  92]\n",
      " [ 10  91]\n",
      " [ 10  90]\n",
      " [ 10  89]\n",
      " [ 10  88]\n",
      " [ 10  87]\n",
      " [ 10  86]\n",
      " [ 11  85]\n",
      " [ 11  84]\n",
      " [ 11  83]\n",
      " [ 11  82]\n",
      " [ 11  81]\n",
      " [ 11  80]\n",
      " [ 11  79]\n",
      " [ 11  78]\n",
      " [ 11  77]\n",
      " [ 11  76]\n",
      " [ 12  75]\n",
      " [ 13  76]\n",
      " [ 14  75]\n",
      " [ 15  74]\n",
      " [ 14  73]\n",
      " [ 13  72]\n",
      " [ 14  71]\n",
      " [ 15  70]\n",
      " [ 16  69]\n",
      " [ 17  68]\n",
      " [ 18  67]\n",
      " [ 19  66]\n",
      " [ 19  65]\n",
      " [ 19  64]\n",
      " [ 20  64]\n",
      " [ 21  64]\n",
      " [ 22  63]\n",
      " [ 23  62]\n",
      " [ 23  61]\n",
      " [ 24  60]\n",
      " [ 24  59]\n",
      " [ 25  58]\n",
      " [ 26  58]\n",
      " [ 27  58]\n",
      " [ 28  57]\n",
      " [ 29  57]\n",
      " [ 30  56]\n",
      " [ 30  55]\n",
      " [ 31  55]\n",
      " [ 32  54]\n",
      " [ 33  54]\n",
      " [ 34  54]\n",
      " [ 35  53]\n",
      " [ 35  52]\n",
      " [ 34  51]\n",
      " [ 35  51]\n",
      " [ 36  51]\n",
      " [ 37  50]\n",
      " [ 38  49]\n",
      " [ 39  49]\n",
      " [ 40  49]\n",
      " [ 41  48]\n",
      " [ 42  47]\n",
      " [ 42  46]\n",
      " [ 42  45]\n",
      " [ 43  45]\n",
      " [ 44  45]\n",
      " [ 45  44]\n",
      " [ 46  43]\n",
      " [ 47  42]\n",
      " [ 48  41]\n",
      " [ 48  40]\n",
      " [ 48  39]\n",
      " [ 48  38]\n",
      " [ 49  37]\n",
      " [ 50  36]\n",
      " [ 51  35]\n",
      " [ 52  34]\n",
      " [ 53  33]\n",
      " [ 54  33]\n",
      " [ 55  32]\n",
      " [ 56  31]\n",
      " [ 55  30]\n",
      " [ 56  30]\n",
      " [ 57  29]\n",
      " [ 57  28]\n",
      " [ 57  27]\n",
      " [ 58  26]\n",
      " [ 58  25]\n",
      " [ 59  25]\n",
      " [ 60  24]\n",
      " [ 60  23]\n",
      " [ 61  22]\n",
      " [ 60  21]\n",
      " [ 59  20]\n",
      " [ 59  19]\n",
      " [ 60  18]\n",
      " [ 61  17]\n",
      " [ 61  16]\n",
      " [ 61  15]\n",
      " [ 62  14]\n",
      " [ 63  13]\n",
      " [ 63  12]\n",
      " [ 63  11]\n",
      " [ 64  11]\n",
      " [ 65  10]\n",
      " [ 66  10]\n",
      " [ 67   9]\n",
      " [ 67   8]\n",
      " [ 67   7]\n",
      " [ 68   7]\n",
      " [ 69   7]\n",
      " [ 70   7]\n",
      " [ 71   8]\n",
      " [ 72   9]\n",
      " [ 73  10]\n",
      " [ 74  10]\n",
      " [ 75  11]\n",
      " [ 76  11]\n",
      " [ 75  12]\n",
      " [ 76  13]\n",
      " [ 77  14]\n",
      " [ 78  15]\n",
      " [ 79  16]\n",
      " [ 80  16]\n",
      " [ 81  16]\n",
      " [ 81  17]\n",
      " [ 81  18]\n",
      " [ 82  19]\n",
      " [ 83  20]\n",
      " [ 84  20]\n",
      " [ 85  20]\n",
      " [ 85  21]\n",
      " [ 85  22]\n",
      " [ 86  23]\n",
      " [ 87  24]\n",
      " [ 88  25]\n",
      " [ 89  26]\n",
      " [ 89  27]\n",
      " [ 89  28]\n",
      " [ 90  29]\n",
      " [ 91  30]\n",
      " [ 91  31]\n",
      " [ 91  32]\n",
      " [ 92  33]\n",
      " [ 93  33]\n",
      " [ 94  34]\n",
      " [ 94  35]\n",
      " [ 95  36]\n",
      " [ 96  37]\n",
      " [ 97  38]\n",
      " [ 98  39]\n",
      " [ 99  40]\n",
      " [ 98  41]\n",
      " [ 99  42]\n",
      " [100  43]\n",
      " [101  43]\n",
      " [102  42]\n",
      " [103  42]\n",
      " [104  42]\n",
      " [105  42]\n",
      " [106  43]\n",
      " [107  43]\n",
      " [108  44]\n",
      " [109  44]\n",
      " [110  45]\n",
      " [111  46]\n",
      " [112  47]\n",
      " [112  48]\n",
      " [113  49]\n",
      " [113  50]\n",
      " [113  51]\n",
      " [113  52]\n",
      " [113  53]\n",
      " [113  54]\n",
      " [113  55]\n",
      " [113  56]\n",
      " [113  57]\n",
      " [112  58]\n",
      " [112  59]\n",
      " [111  60]\n",
      " [110  61]\n",
      " [111  62]\n",
      " [112  63]\n",
      " [112  64]\n",
      " [112  65]\n",
      " [113  66]\n",
      " [114  66]\n",
      " [114  67]\n",
      " [114  68]\n",
      " [114  69]\n",
      " [115  70]\n",
      " [116  70]\n",
      " [117  71]\n",
      " [117  72]\n",
      " [118  73]\n",
      " [118  74]\n",
      " [119  75]\n",
      " [119  76]\n",
      " [119  77]\n",
      " [118  78]\n",
      " [119  79]\n",
      " [120  80]\n",
      " [120  81]\n",
      " [120  82]\n",
      " [121  83]\n",
      " [122  84]\n",
      " [121  85]\n",
      " [122  86]\n",
      " [123  87]\n",
      " [123  88]\n",
      " [123  89]\n",
      " [123  90]\n",
      " [124  91]\n",
      " [124  92]\n",
      " [125  93]\n",
      " [126  94]\n",
      " [125  95]\n",
      " [126  96]\n",
      " [127  97]\n",
      " [127  98]\n",
      " [127  99]\n",
      " [127 100]\n",
      " [127 101]\n",
      " [126 102]\n",
      " [125 103]\n",
      " [124 103]\n",
      " [123 103]\n",
      " [122 103]\n",
      " [121 103]\n",
      " [120 103]\n",
      " [119 103]\n",
      " [118 102]\n",
      " [117 102]\n",
      " [116 103]\n",
      " [115 103]\n",
      " [114 103]\n",
      " [113 103]\n",
      " [112 102]\n",
      " [111 102]\n",
      " [110 102]\n",
      " [109 102]\n",
      " [108 102]\n",
      " [107 102]\n",
      " [106 101]\n",
      " [105 101]\n",
      " [104 101]\n",
      " [103 101]\n",
      " [102 101]\n",
      " [101 101]\n",
      " [100 101]\n",
      " [ 99 101]\n",
      " [ 98 101]\n",
      " [ 97 101]\n",
      " [ 96 102]\n",
      " [ 95 102]\n",
      " [ 94 103]\n",
      " [ 93 103]\n",
      " [ 92 104]\n",
      " [ 91 104]\n",
      " [ 90 105]\n",
      " [ 89 105]\n",
      " [ 88 106]\n",
      " [ 87 107]\n",
      " [ 86 106]\n",
      " [ 85 106]\n",
      " [ 84 106]\n",
      " [ 83 107]\n",
      " [ 82 107]\n",
      " [ 81 107]\n",
      " [ 80 108]\n",
      " [ 79 109]\n",
      " [ 78 110]\n",
      " [ 77 111]\n",
      " [ 76 111]\n",
      " [ 75 111]\n",
      " [ 74 111]\n",
      " [ 73 111]\n",
      " [ 72 112]\n",
      " [ 71 112]\n",
      " [ 70 113]\n",
      " [ 69 113]\n",
      " [ 68 113]\n",
      " [ 67 114]\n",
      " [ 66 114]\n",
      " [ 65 115]\n",
      " [ 64 116]\n",
      " [ 63 116]\n",
      " [ 62 117]\n",
      " [ 61 116]\n",
      " [ 60 117]\n",
      " [ 59 117]\n",
      " [ 58 118]\n",
      " [ 57 118]\n",
      " [ 56 118]\n",
      " [ 55 118]\n",
      " [ 54 119]\n",
      " [ 53 119]\n",
      " [ 52 120]\n",
      " [ 52 121]\n",
      " [ 51 121]\n",
      " [ 50 122]\n",
      " [ 49 121]\n",
      " [ 48 121]\n",
      " [ 47 120]\n",
      " [ 46 121]\n",
      " [ 45 122]\n",
      " [ 44 122]\n",
      " [ 43 122]\n",
      " [ 42 122]\n",
      " [ 41 122]\n",
      " [ 40 122]\n",
      " [ 39 121]\n",
      " [ 38 121]\n",
      " [ 37 122]\n",
      " [ 36 122]\n",
      " [ 35 122]\n",
      " [ 34 121]\n",
      " [ 33 121]\n",
      " [ 32 121]\n",
      " [ 31 120]\n",
      " [ 30 120]\n",
      " [ 30 119]\n",
      " [ 29 118]\n",
      " [ 28 118]\n",
      " [ 28 117]\n",
      " [ 27 116]\n",
      " [ 26 116]\n",
      " [ 25 115]\n",
      " [ 24 116]\n",
      " [ 24 117]\n",
      " [ 24 118]\n",
      " [ 23 119]\n",
      " [ 22 120]\n",
      " [ 21 121]\n",
      " [ 20 122]\n",
      " [ 19 122]\n",
      " [ 18 122]\n",
      " [ 17 122]\n",
      " [ 16 122]\n",
      " [ 15 122]\n",
      " [ 14 122]\n",
      " [ 13 122]\n",
      " [ 12 121]\n",
      " [ 11 121]\n",
      " [ 10 121]\n",
      " [  9 120]\n",
      " [  8 120]\n",
      " [  7 119]\n",
      " [  6 118]\n",
      " [  5 117]\n",
      " [  5 116]\n",
      " [  4 115]\n",
      " [  4 114]\n",
      " [  4 113]\n",
      " [  3 112]\n",
      " [  2 111]\n",
      " [  2 110]\n",
      " [  2 109]\n",
      " [  2 108]\n",
      " [  2 107]\n",
      " [  2 106]\n",
      " [  2 105]\n",
      " [  2 104]\n",
      " [  2 103]\n",
      " [  2 102]]\n"
     ]
    }
   ],
   "source": [
    "print(res_closed_shp[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Functions for persistence diagram construction \n",
    "\n",
    "A function to construct a persistence diagram given a direction is included in the package. The functionality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A persistence diagram is a filtration.  We start with an object and \"build\" the object in a certain direction.  We record when each point in the object first appears (is \"born\") and when it merges into an object that already exists (it \"dies).  Consider the shape below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](full_fig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct this figure in the direction $v = (0,1)$.  If we imagine moving upwards across the figure, the first height at which we will see any points of the diagram is $h=-1$.  We see that vertices 1 and 7 are born at $h = -1$, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![h1](persist_diag1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next height at which something something interesting happens is $h = 0$, at which time three more points are born.  All of these points, however, die immediately.  Vertex 2 merges with vertex 1 and vertices 4 and 5 merge with vertex 7.  At this time we have two unconnected components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](persist_diag2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we reach $h = 1$, we have finished constructing the diagram.  Vertex 6 dies immediately because it merges with vertex 5.  Vertex 3 joints the two components that were previously disjoint.  Since vertices 1 and 7 were both born at $h=-1$, we make a convention that lower numbered vertices will be considered the root and higher numbered vertices will merge with them.  Thus at time $h=1$ vertex 7 dies, as it merges with vertex 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig3](persist_diag3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the persistence diagram is given below.  The red point represents vertex 1, which never dies.  We consider the point to be at $(-1,\\infty)$.  The line in the figure is the diagonal.  A point on the diagonal is one that is born and dies at the same instant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diagram](diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impliment this process of constructing persistene diagrams, we need to be able to tell when a vertex is born and when the vertex merges with another component.  For a fixed direction $v$ (which we will always take to be unit length), we can easily determien the height of a vertex. The height of a vertex $p$ with respect to a direction $v$ is simply the inner product of these two vectors.  The function that calculates the height is given below.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def direction_height(obj, direction):\n",
    "\t\"\"\"\n",
    "\tThis function computes the height of all vertices with\n",
    "\trespect to a specified direction and returns the height \n",
    "\tof each vertex in a dictionary.\n",
    "\n",
    "\tThe function also computes, for each vertex, a list of vertices\n",
    "\tthat are lower (with respect to direction) \n",
    "    \n",
    "    Args:\n",
    "        obj:  An object.  Should be a list of length 2.  The first item in the \n",
    "        list is a matrix where each row is a vertex.  The second item in the list\n",
    "        is a matrix in which each row specifies an (undirected) edge between two \n",
    "        vertices (this matrix has two columns, regardless of the dimension)\n",
    "        \n",
    "        direction: a numpy row vector of appropriate dimension (2 or 3)\n",
    "        \n",
    "    Returns:\n",
    "        dict_heights:  a dictionary that maps v -> height(v) with respect to direction\n",
    "        dict_neighbors:  a dictionary that maps v to a list of lower neighbors.  By lower\n",
    "            neighbors we mean vertices that are connected to v by an edge and have a lower\n",
    "            height than v.  This is convinient information for constructing persistence diagrams\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# this dictionary will contain the vertices that have\n",
    "\t# a lower height with respect to direction\n",
    "\tdict_neighbors = {}\n",
    "\n",
    "\t# this dictionary will map {v : height(v)} for\n",
    "\t# each vertex v\n",
    "\tnum_vert = obj[0].shape[0]\n",
    "\tnum_edges = obj[1].shape[0]\n",
    "\theights = obj[0].dot(direction.T)\n",
    "\tdict_heights = {i+1: heights[i] for i in range(num_vert)}\n",
    "\t# sort vertices by height\t\n",
    "\n",
    "\tdict_neighbors = {v : [] for v in dict_heights.keys()}\n",
    "\n",
    "\t# for each vertex we find all other vertices that lower\n",
    "\t# height with respect to direction \n",
    "\tfor i in range(num_edges):\n",
    "\t\tedge = obj[1][i,:]\n",
    "\t\tif dict_heights[edge[0]] > dict_heights[edge[1]]:\n",
    "\t\t\t# if first vertex is higher than second\n",
    "\t\t\t# add second vertex to list for first\n",
    "\t\t\t# vertex\n",
    "\t\t\tdict_neighbors[edge[0]].append(int(edge[1]))\n",
    "\n",
    "\t\telif dict_heights[edge[0]] == dict_heights[edge[1]]:\n",
    "\t\t\t# if they have the same height, we add the \n",
    "\t\t\t# lower index to the list of the larger index\n",
    "\t\t\tif edge[0] > edge[1]:\n",
    "\t\t\t\tdict_neighbors[edge[0]].append(int(edge[1]))\n",
    "\t\t\t# cannot have edge from vertex to itself\n",
    "\t\t\t# so if above condition is false, we must\n",
    "\t\t\t# have edge[1] > edge[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tdict_neighbors[edge[1]].append(int(edge[0]))\n",
    "\t\t# if other conditions are not met, then edge[1] is\n",
    "\t\t# higher than edge[0]\n",
    "\t\telse:\n",
    "\t\t\tdict_neighbors[edge[1]].append(int(edge[0]))\n",
    "\treturn dict_heights, dict_neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The harder part of the algorithm is determining when components merge.  To keep track of this, we will use a modified version of the Union-Find algorithm.  We define a class called `Tree`.  A `Tree` object has a parent and every tree begins with its own parent.  For convenience, it also has a name.  We will name a tree after a vertex.  So for each vertex $i$ there will be a tree such that `Tree.name = i`.  \n",
    "\n",
    "The function `Find` finds the root of a tree by travelling up the tree until we find a tree that is equal to its parent.  The function `height_Union` joins two trees in a specific way.  If the two input trees have the same root, nothing is done.  If the two trees have different heights, we make the root of one tree equal to the root of the other tree, effectively merging the trees.  As persistence diagrams are built upwards, we make the root of the joint tree the vertex that has the smaller height.  If the vertices have the same height, we make the root the vertex with the lower number.  \n",
    "\n",
    "These functions are used internally and will not be called by a user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "\tdef __init__(self, name):\n",
    "\t\tself.parent = self\n",
    "\t\tself.name = name\n",
    "\t\tself.rank = 0\n",
    "\t\n",
    "def Find(x):\n",
    "\t\"\"\"\n",
    "\tThis function determines the root of the tree\n",
    "\tthat x is in.  It works recursively. x should\n",
    "\tbe an object of class Tree.\n",
    "\t\"\"\"\n",
    "\tif x.parent != x:\n",
    "\t\tx.parent = Find(x.parent)\t\n",
    "\treturn x.parent\n",
    "\n",
    "def height_Union(x, y, dict_heights):\n",
    "\t\"\"\"\n",
    "\tThis function takes the union of two nodes.\n",
    "\tIt does this by changing the root one tree\n",
    "\tto be the root of the other tree.  It changes the\n",
    "\troot based on height.  The root becomes the node with\n",
    "\tthe lowest height.  So the node that is born first\n",
    "\tbecomes the root.  \n",
    "\n",
    "\tIf the two roots have the same height, the lowest \n",
    "\tnumber becomes the root.  For example, if we have vertex\n",
    "\t1 and vertix 3 at the same height, vertex 1 will become\n",
    "\tthe root.  \n",
    "\n",
    "\tInputs:\n",
    "\t\tx,y:  objects of Tree class\n",
    "\t\tdict_heights:  a map v-> h, where v is a vertex,\n",
    "\t\twhich should be the .name of some tree and h is\n",
    "\t\tthe height with respect to some direction\n",
    "        \n",
    "    Returns:\n",
    "        No returns.  Tree objects are merged.\n",
    "\t\"\"\"\n",
    "\tx_root = Find(x)\n",
    "\ty_root = Find(y)\n",
    "\tif x_root == y_root:\n",
    "\t\treturn None\n",
    "\tif dict_heights[x_root.name] < dict_heights[y_root.name]:\n",
    "\t\ty_root.parent = x_root\n",
    "\telif dict_heights[x_root.name] == dict_heights[y_root.name]:\n",
    "\t\tif x.name < y.name:\n",
    "\t\t\ty_root.parent = x_root\n",
    "\t\telse:\n",
    "\t\t\tx_root.parent = y_root\n",
    "\telse:\n",
    "\t\tx_root.parent = y_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a class called `Diagram` to store persistence diagrams.  It has a list of finte points, which will be of the form $(\\text{birth,death})$ and infinite points, which are stored as the birth time.  We have methods to add points to both of these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Diagram:\n",
    "\tdef __init__(self):\n",
    "\t\tself.points = []\n",
    "\t\tself.infpoints = []\n",
    "\tdef addpt(self, pt):\n",
    "\t\tself.points.append(pt)\n",
    "\tdef addinfpt(self, pt):\n",
    "\t\tself.infpoints.append(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that uses this code is `make_diagram`, shown below.  This function increases the height in steps.  At each step we keep track of which vertices have died.  We take the vertices that are born at that height and use `Union` to join them with their lower neighbors.  Using this method we can keep track of when various components merge.    \n",
    "#### (2)  `make_diagram(dict_heights, dict_neighbors) `: Creates a persistence diagram \n",
    "\n",
    "This function uses the output of `direction_height` to create a persistence diagram.  It returns an object of class diagram. This function is used internally and will not be called by the end user.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`dict_heights`: A dictionary mapping a vertex to its height with respect to some direction.\n",
    "\n",
    "`dict_neighbors`:  A dictionar mapping each vertex to a list with vertices that are connected to the vertex and at a lower height.\n",
    "\n",
    "##### Returns:\n",
    "`diag`: An object of class diagram.  \n",
    "\n",
    "##### Function  `make_diagram`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_diagram(dict_heights, dict_neighbors):\n",
    "    \"\"\"\n",
    "    This function uses the output of direction_height to create a persistence diagram. \n",
    "    It returns an object of class diagram. This function is used internally and will \n",
    "    not be called by the end user.\n",
    "    \n",
    "    Parameters:\n",
    "        dict_heights: A dictionary mapping a vertex to its height with respect to some direction.\n",
    "\n",
    "        dict_neighbors: A dictionar mapping each vertex to a list with vertices that are \n",
    "            connected to the vertex and at a lower height.\n",
    "    Returns:\n",
    "        diag: An object of class diagram. \n",
    "    \"\"\"\n",
    "    # create a tree for each vertex\n",
    "    dict_trees = {v: Tree(v) for v in dict_heights.keys()}\n",
    "    # get a set of vertices and a set of heights\n",
    "    vertices = set(dict_heights.keys())\n",
    "    heights = set(dict_heights.values())\n",
    "    # sort the heights, will be unique because of set construction\n",
    "    heights_sorted = sorted(list(heights))\n",
    "    # for each height, we find the vertices that are alive at that height\n",
    "    dict_below_h = {h: [] for h in heights}\n",
    "    for h in heights:\n",
    "        for v in vertices:\n",
    "            if dict_heights[v] <= h:\n",
    "                dict_below_h[h].append(v)\n",
    "    # dictionary that keeps track of deaths\n",
    "    # if a vertex has not died, the value will be None\n",
    "    # if a vertex still has None at the end, it never dies\n",
    "    dict_deaths = {v: None for v in dict_heights.keys()}\n",
    "    # set to hold dead vertices\n",
    "    dead = set()\n",
    "    # if it has a lower neightbor, it dies immediatly\n",
    "    # for all such vertices, we can set the time of death\n",
    "    # to be the time of birth\n",
    "    for v in vertices:\n",
    "        # if it has a lower neightbor\n",
    "        if len(dict_neighbors[v]) != 0:\n",
    "            # it dies at the time it was born\n",
    "            dict_deaths.update({v: dict_heights[v]})\n",
    "            # add it to set of dead vertices\n",
    "            dead.add(v)\n",
    "    # the vertices that are alive are those that do not die instantly\n",
    "    # these are the only onces we need to consider\n",
    "    alive = vertices.difference(dead)\n",
    "    # now we increase the height and merge components as we go\n",
    "    for h in heights_sorted:\n",
    "        # keep track of which vertices die at this height\n",
    "        died = set()\n",
    "        # merge all vertices currently alive with lower vertices\n",
    "        for v in dict_below_h[h]:\n",
    "            for neigh in dict_neighbors[v]:\n",
    "                height_Union(dict_trees[v], dict_trees[neigh],\n",
    "                        dict_heights)\n",
    "        # now we consider all vertices that are still alive\n",
    "        for v in alive:\n",
    "            # check if v is alive (born at height less than h)\n",
    "            if dict_heights[v] <= h:\n",
    "                # boolean:  is v not its own root?\n",
    "                # if it is not its own root, then it must have merged \n",
    "                # with some other class\n",
    "                own_root = v != Find(dict_trees[v]).name\n",
    "                if own_root:\n",
    "                    # has merged with another component\n",
    "                    # record time of death and mark as dead\n",
    "                    died.add(v)\n",
    "                    dict_deaths.update({v: h})\n",
    "        # update set of vertices that are alive\n",
    "        alive = alive.difference(died)\n",
    "    # create an empty diagram\n",
    "    diag = Diagram()\n",
    "    # consider each vertex v\n",
    "    for v in dict_heights.keys():\n",
    "        # if time of death is none, add a point at infinity\n",
    "        if dict_deaths[v] == None:\n",
    "            diag.addinfpt(dict_heights[v])\n",
    "        else:\n",
    "            # only add point if not on the diagonal\n",
    "            # this is designed to reduce the complexity\n",
    "            # of the problem for the Munkres algorithm\n",
    "            if dict_heights[v] != dict_deaths[v]:\n",
    "                diag.addpt((dict_heights[v], dict_deaths[v]))\n",
    "\n",
    "    return diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a diagram, we can consider the distance between diagrams.  If $X$ and $Y$ are diagrams, we can consider bijections $\\phi$ between the points and copies of the diagonal in $X$ with the points and copies of the diagonal in $Y$.  Bijections always exist because there are enought copies of the diagonal to create one.  We define the distance between $X$ and $Y$ to be\n",
    "\\begin{align}\n",
    "dist_p(X,Y) &= \\left(\\inf_{\\phi: X \\to Y}\\sum_{x \\in X} ||x - \\phi(x)||_p^p\\right)^{1/p}.\n",
    "\\end{align}\n",
    "The paper suggests that $p=1$ performs best in practice (the $L1$ norm).  The existence of an optimal bijection is proved in the literature.  An example of an optimal bijection is shown below (taken from www.math.uiuc.edu).  The points of $X$ are shown in red and the points of $Y$ are shown in blue.  The red points are paired with nearby blue points.  Most blue points are paired with their projection onto the diagonal.  In practice, we see that we add the projection onto the diagonal for each point.  This is an optimization problem that can be solved using the Hungarian (Munkres) algorithm.  We can calculate the distance between the points in $X$ and the points in $Y$ and the distance from the points in $X$ to the diagonal.  This can be represented as a cost matrix.  \n",
    "\n",
    "As we will discuss in detail later, this is the bottleneck in our code.  The algorithm is somewhat difficult to implement, so we used an existing implemntation.  Another difficulty is that the first implementation we tried got stuck in an infinite loop.  We settled on using a function from `scipy.optimize`, `linear_sum_assignment`.  This is the distance between the finite points.  We alsoneed to consider the points with one component at infinity.  We will pair these amongst themselves and simply consider the distiance between the birth times.  If two diagrams have a different number of points at infinity, then we would have to pair a point at infinity with a finite point or a point on the diagonal, which is infinitely far away.  The distance between such diagrams is said to be infinite.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diagdist](diagram_distance.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have the code that calculates the distance between the points at infinity.  \n",
    "\n",
    "####  `inf_pt_dist(diagram1, diagram2, q) `: Calculates the distance between essential classes \n",
    "\n",
    "This function computes the distance between the points that correspond to essential classes, i.e. classes where the second component is infinite.  The function assumes that the sets of points are ordered by the first component (the finite one).  If the functions have a different number of such points, the function will print a warning message.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`diagram1`: the first persistence diagram\n",
    "\n",
    "`diagram2`: the second persistence diagram\n",
    "\n",
    "`q`: we use $L_q$ distance\n",
    "\n",
    "##### Returns:\n",
    "`distance`: the distance between the essential classes.  \n",
    "\n",
    "##### Function  `inf_pt_dist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inf_pt_dist(diagram1, diagram2, q):\n",
    "    \"\"\"\n",
    "\tThis function computes the distance between the \n",
    "\tpoints that correspond to essential classes,\n",
    "\ti.e. classes where the second component is infinite\n",
    "\n",
    "\tThis function assumes that the sets of points are\n",
    "\tordered by the first component (the finite one).\n",
    "\tThis should be the case, as points are added to \n",
    "\tthe diagram in this order during construction.\n",
    "\n",
    "\tIf the the diagrams have a different number of points\n",
    "\tat infinity, the distance between them is \n",
    "\tinfinite.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdiagram1:  first persistence diagram\n",
    "\t\tdiagram2:  second persistence diagram\n",
    "\t\tq:  we use L_q distance\n",
    "\n",
    "\tReturn:  distance between points at infinity\n",
    "\t\tfor the two diagrams\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "    n = len(diagram1.infpoints)\n",
    "    m = len(diagram2.infpoints)\n",
    "    number = min(m,n)\n",
    "\n",
    "    if m != n:\n",
    "        print(\"Warning:  different number of points are infinity\")\n",
    "\n",
    "    distance = 0\n",
    "    for i in range(number):\n",
    "        distance += pow(abs(diagram1.infpoints[i] - \n",
    "            diagram2.infpoints[i]), q)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have two simple helper functions, which are unworthy of comment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L1dist(x,y):\n",
    "\t\"\"\"\n",
    "\tThis function computes the L1 distance between\n",
    "\ttwo vectors x and y\n",
    "\t\"\"\"\n",
    "\tc = abs(x[0]-y[0]) + abs(x[1] - y[1])\n",
    "\treturn c\n",
    "\n",
    "def diag_len(x):\n",
    "\t\"\"\"\n",
    "\tThis function calculates the distance from the point\n",
    "\tx (in the persistence diagram) to the diagonal.  This\n",
    "\tfunction uses the L1 distance and will be used in later \n",
    "\tfunctions.\n",
    "\t\"\"\"\n",
    "\treturn x[1] - x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions are used to calculate the distance matrix used to calculate the distance between points.  The distance matrix is not unexpected, except for the addition of the points on the diagonal.  This makes the matrix square.  \n",
    "\n",
    "####  `make_dist_mat(diagram1, diagram2, q) `: Makes distance matrix between points of two diagrams \n",
    "\n",
    "This function constructs a distance between the points of two diagrams, including points on the diagonal.  It returns this distance matrix.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`diagram1`: the first persistence diagram\n",
    "\n",
    "`diagram2`: the second persistence diagram\n",
    "\n",
    "`q`: we use $L_q$ distance\n",
    "\n",
    "##### Returns:\n",
    "`dist_mat`: the distances between the points of the diagram.  \n",
    "\n",
    "##### Function  `make_dist_mat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dist_mat(diagram1, diagram2, q):\n",
    "\t\"\"\"\n",
    "    This function constructs a distance between the points of two diagrams, including points\n",
    "    on the diagonal.  It returns this distance matrix.\n",
    "    \"\"\"\n",
    "\tn = len(diagram1.points)\n",
    "\tm = len(diagram2.points)\n",
    "\tdist_mat = np.zeros((n+m,n+m))\n",
    "\tfor i in range(n):\n",
    "\t\tfor j in range(m):\n",
    "\t\t\t# distance from point i in diagram 1 to joint j in diagram 2\n",
    "\n",
    "\t\t\tdistance = pow(L1dist(diagram1.points[i], diagram2.points[j]),q)\n",
    "\t\t\tdist_mat[i, j] += distance\n",
    "\t\t# distance from point i of diagram 1 to diagonal\n",
    "\t\tdist_to_diag = pow(diag_len(diagram1.points[i]), q)\n",
    "\t\tdist_mat[i, m:][np.newaxis, :] += dist_to_diag*np.ones((1,n))\n",
    "\t\t# now we consider the m copies of the diagonal\n",
    "\tfor j in range(m):\n",
    "\t\t# distiance from jiagonal to point j of diagram 2\n",
    "\t\tdist_to_diag = pow(diag_len(diagram2.points[j]),q)\n",
    "\t\tdist_mat[n:,j][:,np.newaxis] += dist_to_diag*np.ones((m,1))\n",
    "\treturn dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the most computationally intensive function in the code.  This function solves the assignment problem for the finite points of two diagrams.  It uses `linear_sum_assignment` from the python code.\n",
    "\n",
    "#### `finite_pt_dist(diagram1, diagram2, q) `: Calculates the distance between non-essential classes \n",
    "\n",
    "This function computes the smallest distance between the finite points of two persistence diagrams.  This requires matching each point in the first diagram to a point in the second diagram or a point on the diagonal such that the distance between the pairs of points is minimized.  The solution to this problem involves the Munkres (or Hungarian) algorithm, which has already been implemented in Scipy.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`diagram1`: the first persistence diagram\n",
    "\n",
    "`diagram2`: the second persistence diagram\n",
    "\n",
    "`q`: we use $L_q$ distance\n",
    "\n",
    "##### Returns:\n",
    "`distance`: the distance between the non-essential classes.  \n",
    "\n",
    "##### Function  `finite_pt_dist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finite_pt_dist(diagram1, diagram2, q):\n",
    "\t\"\"\"\n",
    "\tThis function computes the smallest distance between the\n",
    "\tfinite points of two persistence diagrams.  This requires\n",
    "\tmatching each point in the first diagram to a point in the \n",
    "\tsecond diagram or a point on the diagonal such that the distance\n",
    "\tbetween the pairs of points is minimized.\n",
    "\n",
    "\tThe solution to this problem involves the Munkres (or Hungarian)\n",
    "\talgorithm, which has already been implemented in Python.\n",
    "\n",
    "\tThis function returns the distanc between the two diagrams\n",
    "    \n",
    "\tArgs:\n",
    "\t\tdiagram1:  first persistence diagram\n",
    "\t\tdiagram2:  second persistence diagram\n",
    "\t\tq:  we use L_q distance\n",
    "\n",
    "\tReturn:  distance between points at infinity\n",
    "\t\tfor the two diagrams\n",
    "\t\"\"\"\n",
    "\n",
    "\tn = len(diagram1.points)\n",
    "\tm = len(diagram2.points)\n",
    "\n",
    "\t# if there are no points, the distance is zero\n",
    "\tif n + m == 0:\n",
    "\t\treturn 0\n",
    "\telse:\n",
    "\t\tdist_mat = make_dist_mat(diagram1, diagram2, q)\n",
    "\t\t# now we can compute the total distance\n",
    "\t\trow_ind, col_ind = linear_sum_assignment(dist_mat)\n",
    "\t\ttotal_dist = 0\n",
    "\t\tfor i in range(len(row_ind)):\n",
    "\t\t\trow = row_ind[i]\n",
    "\t\t\tcol = col_ind[i]\n",
    "\t\t\tvalue = dist_mat[row][col]\n",
    "\t\t\ttotal_dist += value\n",
    "\t\treturn total_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can calculate the distance between two persistence diagrams, we are ready to compute the distance between two objects in $\\mathbb{R}^2$ or $\\mathbb{R}^3$.  For the objects we are considering, the distance (which is indeed a distance based on the results in the paper) is\n",
    "\\begin{align}\n",
    "dist(M_1,M_2) := \\int_{S^{d-1}} dist(X(M_1,v),X(M_2,v))\\,dv,\n",
    "\\end{align}\n",
    "where $X(M_i,v)$ is the persistence diagram for object $M_i$ in direction $v$.  Stability results from the paper reassure that the error in approximating the distance using only a finite sampling of directions should be small.  Thus we approximate this integral by using a sample of points from the circle (in $\\mathbb{R}^2$) or the sphere (in $\\mathbb{R}^3$).  \n",
    "\n",
    "If is often useful to consider objects modulo a group of transformations, typically scaling, rotation, and translation.  Descriptions of how to implement these transformations can be found in the paper.  The code that centers and scales the objects is given below.  Rotation is slightly different.  To calculate the distance modulo rotation, we must consider all possible rotations of the second object and select the one that minimizes the distance.  In practice, we select some finite set of rotations to consider.  Furthermore, we do not actually rotate the object.  Instead, we note that the per\n",
    "\n",
    "####  `center_scale(list_objects, matrix_dir) `: Centers and scales objects with respect to directions \n",
    "\n",
    "This function centers and scales the objects in `list_objects` with respect to the directions in `matrix_dir`.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.  This is the format returned by the functions that read in shape files.\n",
    "\n",
    "`matrix_dir`: a matrix where each direction (on the cirlce or sphere) is a column vector.\n",
    "\n",
    "##### Returns:\n",
    "`list_objects`: a list of objects of the same format as the input, but scaled and centered \n",
    "\n",
    "##### Function  `center_scale`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_scale(list_objects, matrix_dir):\n",
    "\t\"\"\"\n",
    "    This function centers and scales the objects in list_objects with respect to the\n",
    "    directions in matrix_dir\n",
    "    \n",
    "    Args:\n",
    "        list_objects:  a list of objects, specified as pairs of matrices\n",
    "        matrix_dir:  a matrix of directions, each unit vector is a column\n",
    "        \n",
    "    Returns:\n",
    "        A list of scaled and centered objects\n",
    "    \"\"\"\n",
    "\tk = matrix_dir.shape[1]\n",
    "\t# calculate scaling constant\n",
    "\tN = len(list_objects)\n",
    "\tK = 0\n",
    "\tfor i in range(k):\n",
    "\t\tK += np.cos(2*np.pi*i/k)**2\n",
    "\tfor i in range(N):\n",
    "\t\tobj = list_objects[i][0]\n",
    "\t\tprod = obj.dot(matrix_dir)\n",
    "\t\t# minimum of each column is lambda_i\n",
    "\t\tlambdas = prod.min(axis = 0)\n",
    "\t\tu = (1/K)*matrix_dir.dot(lambdas)\n",
    "\t\tlist_objects[i][0] = obj - u[np.newaxis, :]\n",
    "\t\t# now we scale each object\n",
    "\t\tL = -lambdas.sum()\n",
    "\t\tlist_objects[i][0] /= L\n",
    "\treturn list_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will need directions.  These simple functions generate those directions, either uniformly or randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these functions are used to sample directions\n",
    "# the directions are used to construct persistence diagrams\n",
    "# we need to construct persistence diagrams in many directions\n",
    "# the 2-D functions will return exactly n directions, either\n",
    "# randomly generated or evenly spaced\n",
    "# the 3-d functions will return at least n directions\n",
    "def sample_circle(n):\n",
    "\t\"\"\"\n",
    "\tThis function gives evenly spaced directions\n",
    "\ton the cirlce and returns them in a 2 by n \n",
    "\tmatrix.  Each row represents a direction\n",
    "\t\"\"\"\n",
    "\tthetas = np.linspace(0, 2*np.pi, n)\n",
    "\txs = np.cos(thetas)\n",
    "\tys = np.sin(thetas)\n",
    "\tdirections = np.array([xs,ys]).T\n",
    "\treturn directions\n",
    "\n",
    "def random_circle(n):\n",
    "\t\"\"\"\n",
    "\tThis function randomly samples n points on the circle\n",
    "\t\"\"\"\n",
    "\tdraws = np.random.uniform(low=0, high=2*np.pi, size=n)\n",
    "\txs = np.cos(draws)\n",
    "\tys = np.sin(draws)\n",
    "\tdirections = np.array([xs,ys]).T\n",
    "\treturn directions\n",
    "\n",
    "def sample_sphere(n):\n",
    "\t\"\"\"\n",
    "\tThis function returns approximately n points\n",
    "\ton the sphere.  It may return more if n is \n",
    "\tnot a perfect square.  It will always return at \n",
    "\tleast n points.  \n",
    "\t\"\"\"\n",
    "\tN = np.sqrt(n) + 1\n",
    "\tthetas = np.linspace(0, np.pi, N)\n",
    "\tphis = np.linspace(0, 2*np.pi, N)\n",
    "\tpoints = np.meshgrid(thetas, phis)\n",
    "\txs = np.sin(points[0])*np.sin(points[1])\n",
    "\tys = np.sin(points[0])*np.cos(points[1])\n",
    "\tzs = np.cos(points[0])\n",
    "\t\n",
    "\tmatrix = np.vstack([xs.flatten(), ys.flatten(), zs.flatten()]).T\n",
    "\treturn matrix\n",
    "\n",
    "\n",
    "def random_sphere(n):\n",
    "\t\"\"\"\n",
    "\tThis function returns approximately n randomly\n",
    "\tselect points on the sphere.  It may return more if n is \n",
    "\tnot a perfect square.  It will always return at \n",
    "\tleast n points.  \n",
    "\t\"\"\"\n",
    "\tN = np.sqrt(n) + 1\n",
    "\tthetas = np.random.uniform(0, np.pi, N)\n",
    "\tphis = np.random.uniform(0, 2*np.pi, N)\n",
    "\tpoints = np.meshgrid(thetas, phis)\n",
    "\txs = np.sin(points[0])*np.sin(points[1])\n",
    "\tys = np.sin(points[0])*np.cos(points[1])\n",
    "\tzs = np.cos(points[0])\n",
    "\t\n",
    "\tmatrix = np.vstack([xs.flatten(), ys.flatten(), zs.flatten()]).T\n",
    "\treturn matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have code to scale and center, we write two functions to calculate the distance between objects given all necessary persistence diagrams.  The first does not take into account rotation, the second does.  Taking into account rotation involves considering all possible pairs of diagrams.  This is costly, as it involves many repetitions of the slowest part of the code.  First the code without rotation.\n",
    "\n",
    "####  `calculate_distance(i, j, k, l_diagrams)`: Calculates distance between two objects\n",
    "\n",
    "This function calculates the distance between two objects\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`i`: index of first object in l_diagrams\n",
    "`j`: index of second object in l_diagrams\n",
    "`k`: number of directions (number of diagrams for each object)\n",
    "`l_diagrams`:  a list of lists.  Each list contains `k` diagrams for an object.\n",
    "\n",
    "##### Returns:\n",
    "`i,j, actual_dist`:  the inputs `i` and `j` are returned for convience when the code is parallelized. The number `actual_dist` is the distance between the two objects.\n",
    "\n",
    "##### Function  `calculate_distance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_distance(i, j, k, l_diagrams):\n",
    "\t\"\"\"\n",
    "\tThis function calculates the distance between objects i and j in l_diagrams\n",
    "\n",
    "\tArgs:\n",
    "\t\ti:  index of first object\n",
    "\t\tj:  index of second object\n",
    "\t\tk:  number of directions\n",
    "\t\tl_diagrams:  a list of diagrams for each object in each of the\n",
    "\t\t\tk directions\n",
    "\t\n",
    "\tReturn:\n",
    "\t\tThe returns a tuple with 3 number: i, j, and the distance between\n",
    "\t\tthese objects under rotation.  The return of i and j is for convenience\n",
    "\t\tin parallelization.\n",
    "\t\"\"\"\n",
    "\tfinite_dist = 0\n",
    "\tinfinite_dist = 0\n",
    "\tfor c in range(k):\n",
    "\t\tfinite_dist += finite_pt_dist(l_diagrams[i][c],\n",
    "\t\t\t\t\tl_diagrams[j][c], 1)\n",
    "\t\tinfinite_dist += inf_pt_dist(l_diagrams[i][c],\n",
    "\t\t\t\t\tl_diagrams[j][c], 1)\n",
    "\tactual_dist = (finite_dist + infinite_dist)/k\n",
    "\treturn i, j, actual_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a function that calculates the distance modulo rotation. \n",
    "\n",
    "####  `calculate_distance_scale(i, j, k, l_diagrams)`: Calculates distance between two objects\n",
    "\n",
    "This function calculates the distance between two objects modulo rotation.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`i`: index of first object in l_diagrams\n",
    "`j`: index of second object in l_diagrams\n",
    "`k`: number of directions (number of diagrams for each object)\n",
    "`l_diagrams`:  a list of lists.  Each list contains `k` diagrams for an object.\n",
    "\n",
    "##### Returns:\n",
    "`i,j, actual_dist`:  the inputs `i` and `j` are returned for convience when the code is parallelized. The number `actual_dist` is the distance between the two objects.\n",
    "\n",
    "##### Function  `calculate_distance_scale`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_distance_scale(i, j, k, l_diagrams):\n",
    "\t\"\"\"\n",
    "\tThis function calculates the distance between i and j modulo rotation.\n",
    "\tTo do this, we calculate the distance between i and all rotations of j\n",
    "\tand take the minimal distance.  We do not actually rotate the object.\n",
    "\tInstead, we realize that the persistence diagram of a rotation is\n",
    "\tis persistence diagram of a different direction.  Thus we simply rename the \n",
    "\tpersistence diagrams.  \n",
    "\n",
    "\tArgs:\n",
    "\t\ti:  index of first object\n",
    "\t\tj:  index of second object\n",
    "\t\tk:  number of directions\n",
    "\t\tl_diagrams:  a list of diagrams for each object in each of the\n",
    "\t\t\tk directions\n",
    "\t\n",
    "\tReturn:\n",
    "\t\tThe returns a tuple with 3 number: i, j, and the distance between\n",
    "\t\tthese objects under rotation.  The return of i and j is for convenience\n",
    "\t\tin parallelization.\n",
    "\t\"\"\"\n",
    " \t# this list holds the distance between object i and object j under each rotation   \n",
    "\tlist_dists = []\n",
    "\tfor shift in range(k):\n",
    "\t\t# this is the current rotation\n",
    "\t\t# we are considering rotation shift of k\n",
    "\t\tfinite_dist = 0\n",
    "\t\tinfinite_dist = 0\n",
    "\t\tfor cur in range(k):\n",
    "\t\t\t# (cur + shift)%k renumbers the diagram\n",
    "\t\t\t# each diagram moves forward by shift\n",
    "\t\t\t# %k wraps around the end when shift + cur >= k\n",
    "\t\t\tfinite_dist += finite_pt_dist(l_diagrams[i][cur],\n",
    "\t\t\t\t\t\t\t\t\t\t  l_diagrams[j][(cur + shift)%k],\n",
    "\t\t\t\t\t\t\t\t\t\t  1)\n",
    "\t\t\tinfinite_dist += inf_pt_dist(l_diagrams[i][cur],\n",
    "\t\t\t\t\t\t\t\t\t\t l_diagrams[j][(cur + shift)%k],\n",
    "\t\t\t\t\t\t\t\t\t\t 1)\n",
    "\t\tlist_dists.append(finite_dist + infinite_dist)\n",
    "\t# distance is the minimum\n",
    "\tactual_dist = min(list_dists)/k\n",
    "\treturn i, j, actual_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are almost ready to implement the desired functions.  The last function we need is one that calculates all diagrams for a set of shapes in a set of directions.  This function is given below. \n",
    "\n",
    "####  `make_diagrams(list_objects, matrix_dir) `: Makes all diagrams for objects in specified direction \n",
    "\n",
    "This function makes diagrams for all shapes/objects in `list_objects` in all directions in `matrix_dir`.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.  This is the format returned by the functions that read in shape files.\n",
    "\n",
    "`matrix_dir`: a matrix where each direction (on the cirlce or sphere) is a column vector.\n",
    "\n",
    "##### Returns:\n",
    "`l_diagrams`: a list diagrams, one for each object in each direction\n",
    "\n",
    "##### Function  `make_diagrams`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_diagrams(list_objects, matrix_dir):\n",
    "\t\"\"\"\n",
    "    This function makes diagrams for all shapes/objects in list_objects in all\n",
    "    directions in matrix_dir\n",
    "    \n",
    "    Args:\n",
    "        list_objects:  a list of objects, specified as pairs of matrices\n",
    "        matrix_dir:  a matrix of directions, each unit vector is a column\n",
    "        \n",
    "    Returns:\n",
    "        A list of diagrams for all objects in all directions\n",
    "    \"\"\"\n",
    "\tk = matrix_dir.shape[1]\n",
    "\tN = len(list_objects)\n",
    "\tl_diagrams = []\n",
    "\tfor i in range(N):\n",
    "\t\tshape = list_objects[i]\n",
    "\t\tshape_diagrams = []\n",
    "\t\tfor j in range(k):\n",
    "\t\t\tdirection = matrix_dir[:,j].T\n",
    "\t\t\t# make the diagram for jth direction\n",
    "\t\t\td_heights, d_n = direction_height(shape, direction)\n",
    "\t\t\tshape_diagram = make_diagram(d_heights, d_n)\n",
    "\t\t\tshape_diagrams.append(shape_diagram)\n",
    "\t\tl_diagrams.append(shape_diagrams)\n",
    "\treturn l_diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Functions\n",
    "We are now to the main functions that will be run by the end user.  These functions calculate the distance between as set of objects using an approximation with a specified number of directions.  There are four functions in total.  Two that calculate without any scaling (scaling, rotation, and centering) and two that calculate with scaling.  For each pair, one function has parallel processing implemented.  \n",
    "\n",
    "####  `distance_unscaled(list_objects, k) `: Make a distance matrix \n",
    "\n",
    "This function makes a distance matrix for the objects in `list_objects` using `k` directions in the approximation.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.  This is the format returned by the functions that read in shape files.\n",
    "\n",
    "`k`: number of directions to use in approximation\n",
    "\n",
    "##### Returns:\n",
    "`dists`: a distance matrix\n",
    "\n",
    "##### Function  `distance_unscaled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_unscaled(list_objects, k):\n",
    "\t\"\"\"\n",
    "    This function calculates the pairwise distance between all objects in list_objects using k directions\n",
    "    in the approximation\n",
    "    \n",
    "    Args:\n",
    "        list_objects:  a list of objects, specified as pairs of matrices\n",
    "        k: number of directions to use in approximation\n",
    "        \n",
    "    Returns:\n",
    "        A distance matrix\n",
    "    \"\"\"\n",
    "\tN = len(list_objects)\n",
    "\t\n",
    "\tmatrix_dir = sample_circle(k).T\n",
    "\tl_diagrams = make_diagrams(list_objects, matrix_dir)\n",
    "\tdists = np.zeros((N,N))\n",
    "\tfor i in range(N):\n",
    "\t\tfor j in range(i+1,N):\n",
    "\t\t\tr1, r2, dist = calculate_distance(i,j,k,l_diagrams)\n",
    "\t\t\tdists[i,j] = dist\n",
    "\tdists += dists.T\n",
    "\treturn dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A now a version that scales the objects.\n",
    "\n",
    "####  `distance_scaled(list_objects, k) `: Make a distance matrix \n",
    "\n",
    "This function makes a distance matrix for the objects in `list_objects` using `k` directions in the approximation.  The functions scales, centers, and rotates the objects.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.  This is the format returned by the functions that read in shape files.\n",
    "\n",
    "`k`: number of directions to use in approximation\n",
    "\n",
    "##### Returns:\n",
    "`dists`: a distance matrix\n",
    "\n",
    "##### Function  `distance_scaled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_scaled(list_objects, k):\n",
    "\t\"\"\"\n",
    "    This function calculates the pairwise distance between all objects in list_objects using k directions\n",
    "    in the approximation.  It centers, scales, and rotates the objects.\n",
    "    \n",
    "    Args:\n",
    "        list_objects:  a list of objects, specified as pairs of matrices\n",
    "        k: number of directions to use in approximation\n",
    "        \n",
    "    Returns:\n",
    "        A distance matrix\n",
    "    \"\"\"\n",
    "\tN = len(list_objects)\n",
    "\t\n",
    "\tmatrix_dir = sample_circle(k).T\n",
    "\tscaled_objects = center_scale(list_objects, matrix_dir)\n",
    "\tl_diagrams = make_diagrams(scaled_objects, matrix_dir)\n",
    "\tdists = np.zeros((N,N))\n",
    "\tfor i in range(N):\n",
    "\t\tfor j in range(i+1,N):\n",
    "\t\t\tr1, r2, dist = calculate_distance_scale(i, j, k, l_diagrams)\n",
    "\t\t\tdists[i,j] += dist\n",
    "\tdists += dists.T\n",
    "\treturn dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the same functions again, but with the ability to run the tasks in parallel.  \n",
    "\n",
    "####  `distance_unscaled_mc(list_objects, k, workers) `: Make a distance matrix \n",
    "\n",
    "This function makes a distance matrix for the objects in `list_objects` using `k` directions in the approximation.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.  This is the format returned by the functions that read in shape files.\n",
    "\n",
    "`k`: number of directions to use in approximation\n",
    "\n",
    "`workers`:  number of jobs to run in parallel\n",
    "\n",
    "##### Returns:\n",
    "`dist_mat`: a distance matrix\n",
    "\n",
    "##### Function  `distance_unscaled_mc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_unscaled_mc(list_objects, k, workers):\n",
    "\t\"\"\"\n",
    "    This function calculates the pairwise distance between all objects in list_objects using k directions\n",
    "    in the approximation\n",
    "    \n",
    "    Args:\n",
    "        list_objects:  a list of objects, specified as pairs of matrices\n",
    "        k: number of directions to use in approximation\n",
    "        workers:  number of parallel jobs to run\n",
    "        \n",
    "    Returns:\n",
    "        A distance matrix\n",
    "    \"\"\"\n",
    "\t# number of objects\n",
    "\tN = len(list_objects)\n",
    "\t# number of directions\t\n",
    "\tmatrix_dir = sample_circle(k).T\n",
    "\t# now we create a list of diagrams\n",
    "\t# each item in the list is a list of\n",
    "\t# diagrams for one object in each direction\n",
    "\t# so it is a list of length N with sublists\n",
    "\t# of size k\n",
    "\tl_diagrams = make_diagrams(list_objects, matrix_dir)\n",
    "\tdist_mat = np.zeros((N,N))\n",
    "\tlist_inputs = [(i, j, k, l_diagrams) for i in range(N)\n",
    "\t\t\t\t\t\t\t\t\t\t for j in range(i+1, N)]\n",
    "\twith mp.Pool(processes=workers) as pool:\n",
    "\t\tdistances = pool.starmap(calculate_distance, list_inputs)\n",
    "\tfor tup in distances:\n",
    "\t\tdist_mat[tup[0],tup[1]] = tup[2]\n",
    "\tdist_mat += dist_mat.T\n",
    "\treturn dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a scaled version that is also parallel.  \n",
    "\n",
    "####  `distance_scaled_mc(list_objects, k, workers) `: Make a distance matrix \n",
    "\n",
    "This function makes a distance matrix for the objects in `list_objects` using `k` directions in the approximation.  It centers, scales, and rotates the objects\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "`list_objects`: A list of lists. Each embedded list contains two `numpy.ndarray`'s: the first array contains the coordinates of the vertices of one shape; the second contains the location of the edges of the shape.  This is the format returned by the functions that read in shape files.\n",
    "\n",
    "`k`: number of directions to use in approximation\n",
    "\n",
    "`workers`:  number of jobs to run in parallel\n",
    "\n",
    "##### Returns:\n",
    "`dist_mat`: a distance matrix\n",
    "\n",
    "##### Function  `distance_scaled_mc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_scaled_mc(list_objects, k, workers):\n",
    "\t\"\"\"\n",
    "    This function calculates the pairwise distance between all objects in list_objects using k directions\n",
    "    in the approximation.  It centers, scales, and rotates the objects\n",
    "    \n",
    "    Args:\n",
    "        list_objects:  a list of objects, specified as pairs of matrices\n",
    "        k: number of directions to use in approximation\n",
    "        workers:  number of parallel jobs to run\n",
    "        \n",
    "    Returns:\n",
    "        A distance matrix\n",
    "    \"\"\"\n",
    "\t# number of objects\n",
    "\tN = len(list_objects)\n",
    "\t# number of directions\t\n",
    "\tmatrix_dir = sample_circle(k).T\n",
    "\t# compute centering constant\n",
    "\tscaled_objects = center_scale(list_objects, matrix_dir)\n",
    "\t# now we create a list of diagrams\n",
    "\t# each item in the list is a list of\n",
    "\t# diagrams for one object in each direction\n",
    "\t# so it is a list of length N with sublists\n",
    "\t# of size k\n",
    "\tl_diagrams = make_diagrams(scaled_objects, matrix_dir)\n",
    "\tdist_mat = np.zeros((N,N))\n",
    "\tlist_inputs = [(i, j, k, l_diagrams) for i in range(N)\n",
    "\t\t\t\t\t\t\t\t\t\t for j in range(i+1, N)]\n",
    "\twith mp.Pool(processes=workers) as pool:\n",
    "\t\tdistances = pool.starmap(calculate_distance_scale, list_inputs)\n",
    "\tfor tup in distances:\n",
    "\t\tdist_mat[tup[0],tup[1]] = tup[2]\n",
    "\tdist_mat += dist_mat.T\n",
    "\treturn dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Algorithms\n",
    "---\n",
    "One algorithm used is the Hungarian (or Munkres) algorithm.  The alogirthm is used in situations where assignments with an associated cost must be made and the goal is to select the assignment to minimize the cost.  Here we use this algorithm to calculate the distance between persistence diagrams. The distance between persistence diagrams is the sum of the distances between the points of the first persistence diagram paired with the points of the second diagram and additional points on the diagonal.  Selecting the pairing that minimzies this distance can be achieved using the Munkres algorithm.\n",
    "\n",
    "Another algorithm used in our code is the Union-Find algorithm.  This algorithm is used in the construction of the persistence diagrams. During the construction we must keep track of when disjoint components merge.  We view each component as a tree.  When two components merge we join the roots of the trees.  This allows us to find when disjoint components merge.\n",
    "\n",
    "Section 4:  Tests\n",
    "---\n",
    "Write some tests. In particular, compare results from our codes to results in the paper to ensure that our codes yield the same results.  Test on simple simulated data.\n",
    "\n",
    "Section 5:  Optimization\n",
    "---\n",
    "#### Part 1: compilation optimization\n",
    "We tried optimizing the performance of the codes using `numba` just-in-time (JIT) compilation, `Cython`, embarrasingly parallel processing. Based on the input file `Class1_Sample1.mat`, most functions perform very well, taking only miliseconds to process such a shape with $375$ vertices. Assuming we want to measure the distance between such a shape to another shape with $375$ vertices, it takes $33.6s$ for the current Munkres algorithm to finish running, suggesting room for improvement.\n",
    "\n",
    "We used the function `linear_sum_assignment` (Source: https://github.com/scipy/scipy/blob/master/scipy/optimize/_hungarian.py#L13-L107`scipy) from `scipy.optimize`. To improve its performance, we tried numba JIT computation, simple compilation in `Cython`, cythonizing via static typing and `cnumpy` iteration and wrapping `C` codes. However, no correct and easily accessible `C` or `C++` functions have been found. Neither have we achieve significant improvement in `Python`. Specifically, the major problem in cythonizing concerns the fast array declarations in `cdef` classes. Fast array declarations, however, are currently not accessible in the fields of cdef classes or as global variables, according to Cython documentation\n",
    "(ref: http://cython.readthedocs.io/en/latest/src/tutorial/numpy.html).\n",
    "\n",
    "We benchmarked the different optimization strategies based on a $1,000 \\times 1,000$ cost matrix. The performances are  summarised in the table below:\n",
    "\n",
    "|  | original function | numba JIT  | Simple Cython compilation | Cythonizing via static typing & `cNumPy` |\n",
    "|-----------|-------------------|------------|---------------------------|------------------------------------------|\n",
    "| Wall time | 1 min 41 s        | 1 min 27 s | 1 min 46 s                | 1 min 42 s                               |\n",
    "\n",
    "\n",
    "As can be seen from the above table, no consistent outperformance has been achieved. \n",
    "\n",
    "#### Part 2: algorithm optimization\n",
    "\n",
    "We speeded up the function `make_diagram` via better algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
